// Code generated by cue get go. DO NOT EDIT.

//cue:generate cue get go github.com/upbound/provider-gcp/apis/monitoring/v1beta1

package v1beta1

#AggregationsInitParameters: {
	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	alignmentPeriod?: null | string @go(AlignmentPeriod,*string)

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	crossSeriesReducer?: null | string @go(CrossSeriesReducer,*string)

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	groupByFields?: [...null | string] @go(GroupByFields,[]*string)

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	perSeriesAligner?: null | string @go(PerSeriesAligner,*string)
}

#AggregationsObservation: {
	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	alignmentPeriod?: null | string @go(AlignmentPeriod,*string)

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	crossSeriesReducer?: null | string @go(CrossSeriesReducer,*string)

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	groupByFields?: [...null | string] @go(GroupByFields,[]*string)

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	perSeriesAligner?: null | string @go(PerSeriesAligner,*string)
}

#AggregationsParameters: {
	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	// +kubebuilder:validation:Optional
	alignmentPeriod?: null | string @go(AlignmentPeriod,*string)

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	// +kubebuilder:validation:Optional
	crossSeriesReducer?: null | string @go(CrossSeriesReducer,*string)

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	// +kubebuilder:validation:Optional
	groupByFields?: [...null | string] @go(GroupByFields,[]*string)

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	// +kubebuilder:validation:Optional
	perSeriesAligner?: null | string @go(PerSeriesAligner,*string)
}

#AlertPolicyInitParameters: {
	// Control over how this alert policy's notification channels are notified.
	// Structure is documented below.
	alertStrategy?: [...#AlertStrategyInitParameters] @go(AlertStrategy,[]AlertStrategyInitParameters)

	// How to combine the results of multiple conditions to
	// determine if an incident should be opened.
	// Possible values are: AND, OR, AND_WITH_MATCHING_RESOURCE.
	combiner?: null | string @go(Combiner,*string)

	// A list of conditions for the policy. The conditions are combined by
	// AND or OR according to the combiner field. If the combined conditions
	// evaluate to true, then an incident is created. A policy can have from
	// one to six conditions.
	// Structure is documented below.
	conditions?: [...#ConditionsInitParameters] @go(Conditions,[]ConditionsInitParameters)

	// A short name or phrase used to identify the policy in
	// dashboards, notifications, and incidents. To avoid confusion, don't use
	// the same display name for multiple policies in the same project. The
	// name is limited to 512 Unicode characters.
	displayName?: null | string @go(DisplayName,*string)

	// Documentation that is included with notifications and incidents related
	// to this policy. Best practice is for the documentation to include information
	// to help responders understand, mitigate, escalate, and correct the underlying
	// problems detected by the alerting policy. Notification channels that have
	// limited capacity might not show this documentation.
	// Structure is documented below.
	documentation?: [...#DocumentationInitParameters] @go(Documentation,[]DocumentationInitParameters)

	// Whether or not the policy is enabled. The default is true.
	enabled?: null | bool @go(Enabled,*bool)

	// Identifies the notification channels to which notifications should be
	// sent when incidents are opened or closed or when new violations occur
	// on an already opened incident. Each element of this array corresponds
	// to the name field in each of the NotificationChannel objects that are
	// returned from the notificationChannels.list method. The syntax of the
	// entries in this field is
	// projects/[PROJECT_ID]/notificationChannels/[CHANNEL_ID]
	notificationChannels?: [...null | string] @go(NotificationChannels,[]*string)

	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	project?: null | string @go(Project,*string)

	// This field is intended to be used for organizing and identifying the AlertPolicy
	// objects.The field can contain up to 64 entries. Each key and value is limited
	// to 63 Unicode characters or 128 bytes, whichever is smaller. Labels and values
	// can contain only lowercase letters, numerals, underscores, and dashes. Keys
	// must begin with a letter.
	userLabels?: {[string]: null | string} @go(UserLabels,map[string]*string)
}

#AlertPolicyObservation: {
	// Control over how this alert policy's notification channels are notified.
	// Structure is documented below.
	alertStrategy?: [...#AlertStrategyObservation] @go(AlertStrategy,[]AlertStrategyObservation)

	// How to combine the results of multiple conditions to
	// determine if an incident should be opened.
	// Possible values are: AND, OR, AND_WITH_MATCHING_RESOURCE.
	combiner?: null | string @go(Combiner,*string)

	// A list of conditions for the policy. The conditions are combined by
	// AND or OR according to the combiner field. If the combined conditions
	// evaluate to true, then an incident is created. A policy can have from
	// one to six conditions.
	// Structure is documented below.
	conditions?: [...#ConditionsObservation] @go(Conditions,[]ConditionsObservation)

	// A read-only record of the creation of the alerting policy.
	// If provided in a call to create or update, this field will
	// be ignored.
	// Structure is documented below.
	creationRecord?: [...#CreationRecordObservation] @go(CreationRecord,[]CreationRecordObservation)

	// A short name or phrase used to identify the policy in
	// dashboards, notifications, and incidents. To avoid confusion, don't use
	// the same display name for multiple policies in the same project. The
	// name is limited to 512 Unicode characters.
	displayName?: null | string @go(DisplayName,*string)

	// Documentation that is included with notifications and incidents related
	// to this policy. Best practice is for the documentation to include information
	// to help responders understand, mitigate, escalate, and correct the underlying
	// problems detected by the alerting policy. Notification channels that have
	// limited capacity might not show this documentation.
	// Structure is documented below.
	documentation?: [...#DocumentationObservation] @go(Documentation,[]DocumentationObservation)

	// Whether or not the policy is enabled. The default is true.
	enabled?: null | bool @go(Enabled,*bool)

	// an identifier for the resource with format {{name}}
	id?: null | string @go(ID,*string)

	// The unique resource name for this policy.
	// Its syntax is: projects/[PROJECT_ID]/alertPolicies/[ALERT_POLICY_ID]
	name?: null | string @go(Name,*string)

	// Identifies the notification channels to which notifications should be
	// sent when incidents are opened or closed or when new violations occur
	// on an already opened incident. Each element of this array corresponds
	// to the name field in each of the NotificationChannel objects that are
	// returned from the notificationChannels.list method. The syntax of the
	// entries in this field is
	// projects/[PROJECT_ID]/notificationChannels/[CHANNEL_ID]
	notificationChannels?: [...null | string] @go(NotificationChannels,[]*string)

	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	project?: null | string @go(Project,*string)

	// This field is intended to be used for organizing and identifying the AlertPolicy
	// objects.The field can contain up to 64 entries. Each key and value is limited
	// to 63 Unicode characters or 128 bytes, whichever is smaller. Labels and values
	// can contain only lowercase letters, numerals, underscores, and dashes. Keys
	// must begin with a letter.
	userLabels?: {[string]: null | string} @go(UserLabels,map[string]*string)
}

#AlertPolicyParameters: {
	// Control over how this alert policy's notification channels are notified.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	alertStrategy?: [...#AlertStrategyParameters] @go(AlertStrategy,[]AlertStrategyParameters)

	// How to combine the results of multiple conditions to
	// determine if an incident should be opened.
	// Possible values are: AND, OR, AND_WITH_MATCHING_RESOURCE.
	// +kubebuilder:validation:Optional
	combiner?: null | string @go(Combiner,*string)

	// A list of conditions for the policy. The conditions are combined by
	// AND or OR according to the combiner field. If the combined conditions
	// evaluate to true, then an incident is created. A policy can have from
	// one to six conditions.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	conditions?: [...#ConditionsParameters] @go(Conditions,[]ConditionsParameters)

	// A short name or phrase used to identify the policy in
	// dashboards, notifications, and incidents. To avoid confusion, don't use
	// the same display name for multiple policies in the same project. The
	// name is limited to 512 Unicode characters.
	// +kubebuilder:validation:Optional
	displayName?: null | string @go(DisplayName,*string)

	// Documentation that is included with notifications and incidents related
	// to this policy. Best practice is for the documentation to include information
	// to help responders understand, mitigate, escalate, and correct the underlying
	// problems detected by the alerting policy. Notification channels that have
	// limited capacity might not show this documentation.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	documentation?: [...#DocumentationParameters] @go(Documentation,[]DocumentationParameters)

	// Whether or not the policy is enabled. The default is true.
	// +kubebuilder:validation:Optional
	enabled?: null | bool @go(Enabled,*bool)

	// Identifies the notification channels to which notifications should be
	// sent when incidents are opened or closed or when new violations occur
	// on an already opened incident. Each element of this array corresponds
	// to the name field in each of the NotificationChannel objects that are
	// returned from the notificationChannels.list method. The syntax of the
	// entries in this field is
	// projects/[PROJECT_ID]/notificationChannels/[CHANNEL_ID]
	// +kubebuilder:validation:Optional
	notificationChannels?: [...null | string] @go(NotificationChannels,[]*string)

	// The ID of the project in which the resource belongs.
	// If it is not provided, the provider project is used.
	// +kubebuilder:validation:Optional
	project?: null | string @go(Project,*string)

	// This field is intended to be used for organizing and identifying the AlertPolicy
	// objects.The field can contain up to 64 entries. Each key and value is limited
	// to 63 Unicode characters or 128 bytes, whichever is smaller. Labels and values
	// can contain only lowercase letters, numerals, underscores, and dashes. Keys
	// must begin with a letter.
	// +kubebuilder:validation:Optional
	userLabels?: {[string]: null | string} @go(UserLabels,map[string]*string)
}

#AlertStrategyInitParameters: {
	// If an alert policy that was active has no data for this long, any open incidents will close.
	autoClose?: null | string @go(AutoClose,*string)

	// Control over how the notification channels in notification_channels
	// are notified when this alert fires, on a per-channel basis.
	// Structure is documented below.
	notificationChannelStrategy?: [...#NotificationChannelStrategyInitParameters] @go(NotificationChannelStrategy,[]NotificationChannelStrategyInitParameters)

	// Required for alert policies with a LogMatch condition.
	// This limit is not implemented for alert policies that are not log-based.
	// Structure is documented below.
	notificationRateLimit?: [...#NotificationRateLimitInitParameters] @go(NotificationRateLimit,[]NotificationRateLimitInitParameters)
}

#AlertStrategyObservation: {
	// If an alert policy that was active has no data for this long, any open incidents will close.
	autoClose?: null | string @go(AutoClose,*string)

	// Control over how the notification channels in notification_channels
	// are notified when this alert fires, on a per-channel basis.
	// Structure is documented below.
	notificationChannelStrategy?: [...#NotificationChannelStrategyObservation] @go(NotificationChannelStrategy,[]NotificationChannelStrategyObservation)

	// Required for alert policies with a LogMatch condition.
	// This limit is not implemented for alert policies that are not log-based.
	// Structure is documented below.
	notificationRateLimit?: [...#NotificationRateLimitObservation] @go(NotificationRateLimit,[]NotificationRateLimitObservation)
}

#AlertStrategyParameters: {
	// If an alert policy that was active has no data for this long, any open incidents will close.
	// +kubebuilder:validation:Optional
	autoClose?: null | string @go(AutoClose,*string)

	// Control over how the notification channels in notification_channels
	// are notified when this alert fires, on a per-channel basis.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	notificationChannelStrategy?: [...#NotificationChannelStrategyParameters] @go(NotificationChannelStrategy,[]NotificationChannelStrategyParameters)

	// Required for alert policies with a LogMatch condition.
	// This limit is not implemented for alert policies that are not log-based.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	notificationRateLimit?: [...#NotificationRateLimitParameters] @go(NotificationRateLimit,[]NotificationRateLimitParameters)
}

#ConditionAbsentInitParameters: {
	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	aggregations?: [...#AggregationsInitParameters] @go(Aggregations,[]AggregationsInitParameters)

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	duration?: null | string @go(Duration,*string)

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	filter?: null | string @go(Filter,*string)

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	trigger?: [...#TriggerInitParameters] @go(Trigger,[]TriggerInitParameters)
}

#ConditionAbsentObservation: {
	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	aggregations?: [...#AggregationsObservation] @go(Aggregations,[]AggregationsObservation)

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	duration?: null | string @go(Duration,*string)

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	filter?: null | string @go(Filter,*string)

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	trigger?: [...#TriggerObservation] @go(Trigger,[]TriggerObservation)
}

#ConditionAbsentParameters: {
	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	aggregations?: [...#AggregationsParameters] @go(Aggregations,[]AggregationsParameters)

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	// +kubebuilder:validation:Optional
	duration?: null | string @go(Duration,*string)

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	// +kubebuilder:validation:Optional
	filter?: null | string @go(Filter,*string)

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	trigger?: [...#TriggerParameters] @go(Trigger,[]TriggerParameters)
}

#ConditionMatchedLogInitParameters: {
	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	filter?: null | string @go(Filter,*string)

	// A map from a label key to an extractor expression, which is used to
	// extract the value for this label key. Each entry in this map is
	// a specification for how data should be extracted from log entries that
	// match filter. Each combination of extracted values is treated as
	// a separate rule for the purposes of triggering notifications.
	// Label keys and corresponding values can be used in notifications
	// generated by this condition.
	labelExtractors?: {[string]: null | string} @go(LabelExtractors,map[string]*string)
}

#ConditionMatchedLogObservation: {
	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	filter?: null | string @go(Filter,*string)

	// A map from a label key to an extractor expression, which is used to
	// extract the value for this label key. Each entry in this map is
	// a specification for how data should be extracted from log entries that
	// match filter. Each combination of extracted values is treated as
	// a separate rule for the purposes of triggering notifications.
	// Label keys and corresponding values can be used in notifications
	// generated by this condition.
	labelExtractors?: {[string]: null | string} @go(LabelExtractors,map[string]*string)
}

#ConditionMatchedLogParameters: {
	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	// +kubebuilder:validation:Optional
	filter?: null | string @go(Filter,*string)

	// A map from a label key to an extractor expression, which is used to
	// extract the value for this label key. Each entry in this map is
	// a specification for how data should be extracted from log entries that
	// match filter. Each combination of extracted values is treated as
	// a separate rule for the purposes of triggering notifications.
	// Label keys and corresponding values can be used in notifications
	// generated by this condition.
	// +kubebuilder:validation:Optional
	labelExtractors?: {[string]: null | string} @go(LabelExtractors,map[string]*string)
}

#ConditionMonitoringQueryLanguageInitParameters: {
	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	duration?: null | string @go(Duration,*string)

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	evaluationMissingData?: null | string @go(EvaluationMissingData,*string)

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	query?: null | string @go(Query,*string)

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	trigger?: [...#ConditionMonitoringQueryLanguageTriggerInitParameters] @go(Trigger,[]ConditionMonitoringQueryLanguageTriggerInitParameters)
}

#ConditionMonitoringQueryLanguageObservation: {
	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	duration?: null | string @go(Duration,*string)

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	evaluationMissingData?: null | string @go(EvaluationMissingData,*string)

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	query?: null | string @go(Query,*string)

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	trigger?: [...#ConditionMonitoringQueryLanguageTriggerObservation] @go(Trigger,[]ConditionMonitoringQueryLanguageTriggerObservation)
}

#ConditionMonitoringQueryLanguageParameters: {
	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	// +kubebuilder:validation:Optional
	duration?: null | string @go(Duration,*string)

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	// +kubebuilder:validation:Optional
	evaluationMissingData?: null | string @go(EvaluationMissingData,*string)

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	// +kubebuilder:validation:Optional
	query?: null | string @go(Query,*string)

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	trigger?: [...#ConditionMonitoringQueryLanguageTriggerParameters] @go(Trigger,[]ConditionMonitoringQueryLanguageTriggerParameters)
}

#ConditionMonitoringQueryLanguageTriggerInitParameters: {
	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	count?: null | float64 @go(Count,*float64)

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	percent?: null | float64 @go(Percent,*float64)
}

#ConditionMonitoringQueryLanguageTriggerObservation: {
	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	count?: null | float64 @go(Count,*float64)

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	percent?: null | float64 @go(Percent,*float64)
}

#ConditionMonitoringQueryLanguageTriggerParameters: {
	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	count?: null | float64 @go(Count,*float64)

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	percent?: null | float64 @go(Percent,*float64)
}

#ConditionPrometheusQueryLanguageInitParameters: {
	// The alerting rule name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	alertRule?: null | string @go(AlertRule,*string)

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	duration?: null | string @go(Duration,*string)

	// How often this rule should be evaluated. Must be a positive multiple
	// of 30 seconds or missing. The default value is 30 seconds. If this
	// PrometheusQueryLanguageCondition was generated from a Prometheus
	// alerting rule, then this value should be taken from the enclosing
	// rule group.
	evaluationInterval?: null | string @go(EvaluationInterval,*string)

	// Labels to add to or overwrite in the PromQL query result. Label names
	// must be valid.
	// Label values can be templatized by using variables. The only available
	// variable names are the names of the labels in the PromQL result, including
	// "name" and "value". "labels" may be empty. This field is intended to be
	// used for organizing and identifying the AlertPolicy
	labels?: {[string]: null | string} @go(Labels,map[string]*string)

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	query?: null | string @go(Query,*string)

	// The rule group name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	ruleGroup?: null | string @go(RuleGroup,*string)
}

#ConditionPrometheusQueryLanguageObservation: {
	// The alerting rule name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	alertRule?: null | string @go(AlertRule,*string)

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	duration?: null | string @go(Duration,*string)

	// How often this rule should be evaluated. Must be a positive multiple
	// of 30 seconds or missing. The default value is 30 seconds. If this
	// PrometheusQueryLanguageCondition was generated from a Prometheus
	// alerting rule, then this value should be taken from the enclosing
	// rule group.
	evaluationInterval?: null | string @go(EvaluationInterval,*string)

	// Labels to add to or overwrite in the PromQL query result. Label names
	// must be valid.
	// Label values can be templatized by using variables. The only available
	// variable names are the names of the labels in the PromQL result, including
	// "name" and "value". "labels" may be empty. This field is intended to be
	// used for organizing and identifying the AlertPolicy
	labels?: {[string]: null | string} @go(Labels,map[string]*string)

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	query?: null | string @go(Query,*string)

	// The rule group name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	ruleGroup?: null | string @go(RuleGroup,*string)
}

#ConditionPrometheusQueryLanguageParameters: {
	// The alerting rule name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	// +kubebuilder:validation:Optional
	alertRule?: null | string @go(AlertRule,*string)

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	// +kubebuilder:validation:Optional
	duration?: null | string @go(Duration,*string)

	// How often this rule should be evaluated. Must be a positive multiple
	// of 30 seconds or missing. The default value is 30 seconds. If this
	// PrometheusQueryLanguageCondition was generated from a Prometheus
	// alerting rule, then this value should be taken from the enclosing
	// rule group.
	// +kubebuilder:validation:Optional
	evaluationInterval?: null | string @go(EvaluationInterval,*string)

	// Labels to add to or overwrite in the PromQL query result. Label names
	// must be valid.
	// Label values can be templatized by using variables. The only available
	// variable names are the names of the labels in the PromQL result, including
	// "name" and "value". "labels" may be empty. This field is intended to be
	// used for organizing and identifying the AlertPolicy
	// +kubebuilder:validation:Optional
	labels?: {[string]: null | string} @go(Labels,map[string]*string)

	// The PromQL expression to evaluate. Every evaluation cycle this
	// expression is evaluated at the current time, and all resultant time
	// series become pending/firing alerts. This field must not be empty.
	// +kubebuilder:validation:Optional
	query?: null | string @go(Query,*string)

	// The rule group name of this alert in the corresponding Prometheus
	// configuration file.
	// Some external tools may require this field to be populated correctly
	// in order to refer to the original Prometheus configuration file.
	// The rule group name and the alert name are necessary to update the
	// relevant AlertPolicies in case the definition of the rule group changes
	// in the future.
	// This field is optional. If this field is not empty, then it must be a
	// valid Prometheus label name.
	// +kubebuilder:validation:Optional
	ruleGroup?: null | string @go(RuleGroup,*string)
}

#ConditionThresholdAggregationsInitParameters: {
	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	alignmentPeriod?: null | string @go(AlignmentPeriod,*string)

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	crossSeriesReducer?: null | string @go(CrossSeriesReducer,*string)

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	groupByFields?: [...null | string] @go(GroupByFields,[]*string)

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	perSeriesAligner?: null | string @go(PerSeriesAligner,*string)
}

#ConditionThresholdAggregationsObservation: {
	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	alignmentPeriod?: null | string @go(AlignmentPeriod,*string)

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	crossSeriesReducer?: null | string @go(CrossSeriesReducer,*string)

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	groupByFields?: [...null | string] @go(GroupByFields,[]*string)

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	perSeriesAligner?: null | string @go(PerSeriesAligner,*string)
}

#ConditionThresholdAggregationsParameters: {
	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	// +kubebuilder:validation:Optional
	alignmentPeriod?: null | string @go(AlignmentPeriod,*string)

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	// +kubebuilder:validation:Optional
	crossSeriesReducer?: null | string @go(CrossSeriesReducer,*string)

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	// +kubebuilder:validation:Optional
	groupByFields?: [...null | string] @go(GroupByFields,[]*string)

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	// +kubebuilder:validation:Optional
	perSeriesAligner?: null | string @go(PerSeriesAligner,*string)
}

#ConditionThresholdInitParameters: {
	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	aggregations?: [...#ConditionThresholdAggregationsInitParameters] @go(Aggregations,[]ConditionThresholdAggregationsInitParameters)

	// The comparison to apply between the time
	// series (indicated by filter and aggregation)
	// and the threshold (indicated by
	// threshold_value). The comparison is applied
	// on each time series, with the time series on
	// the left-hand side and the threshold on the
	// right-hand side. Only COMPARISON_LT and
	// COMPARISON_GT are supported currently.
	// Possible values are: COMPARISON_GT, COMPARISON_GE, COMPARISON_LT, COMPARISON_LE, COMPARISON_EQ, COMPARISON_NE.
	comparison?: null | string @go(Comparison,*string)

	// Specifies the alignment of data points in
	// individual time series selected by
	// denominatorFilter as well as how to combine
	// the retrieved time series together (such as
	// when aggregating multiple streams on each
	// resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).When
	// computing ratios, the aggregations and
	// denominator_aggregations fields must use the
	// same alignment period and produce time
	// series that have the same periodicity and
	// labels.This field is similar to the one in
	// the MetricService.ListTimeSeries request. It
	// is advisable to use the ListTimeSeries
	// method when debugging this field.
	// Structure is documented below.
	denominatorAggregations?: [...#DenominatorAggregationsInitParameters] @go(DenominatorAggregations,[]DenominatorAggregationsInitParameters)

	// A filter that identifies a time series that
	// should be used as the denominator of a ratio
	// that will be compared with the threshold. If
	// a denominator_filter is specified, the time
	// series specified by the filter field will be
	// used as the numerator.The filter is similar
	// to the one that is specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	denominatorFilter?: null | string @go(DenominatorFilter,*string)

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	duration?: null | string @go(Duration,*string)

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	evaluationMissingData?: null | string @go(EvaluationMissingData,*string)

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	filter?: null | string @go(Filter,*string)

	// When this field is present, the MetricThreshold
	// condition forecasts whether the time series is
	// predicted to violate the threshold within the
	// forecastHorizon. When this field is not set, the
	// MetricThreshold tests the current value of the
	// timeseries against the threshold.
	// Structure is documented below.
	forecastOptions?: [...#ForecastOptionsInitParameters] @go(ForecastOptions,[]ForecastOptionsInitParameters)

	// A value against which to compare the time
	// series.
	thresholdValue?: null | float64 @go(ThresholdValue,*float64)

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	trigger?: [...#ConditionThresholdTriggerInitParameters] @go(Trigger,[]ConditionThresholdTriggerInitParameters)
}

#ConditionThresholdObservation: {
	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	aggregations?: [...#ConditionThresholdAggregationsObservation] @go(Aggregations,[]ConditionThresholdAggregationsObservation)

	// The comparison to apply between the time
	// series (indicated by filter and aggregation)
	// and the threshold (indicated by
	// threshold_value). The comparison is applied
	// on each time series, with the time series on
	// the left-hand side and the threshold on the
	// right-hand side. Only COMPARISON_LT and
	// COMPARISON_GT are supported currently.
	// Possible values are: COMPARISON_GT, COMPARISON_GE, COMPARISON_LT, COMPARISON_LE, COMPARISON_EQ, COMPARISON_NE.
	comparison?: null | string @go(Comparison,*string)

	// Specifies the alignment of data points in
	// individual time series selected by
	// denominatorFilter as well as how to combine
	// the retrieved time series together (such as
	// when aggregating multiple streams on each
	// resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).When
	// computing ratios, the aggregations and
	// denominator_aggregations fields must use the
	// same alignment period and produce time
	// series that have the same periodicity and
	// labels.This field is similar to the one in
	// the MetricService.ListTimeSeries request. It
	// is advisable to use the ListTimeSeries
	// method when debugging this field.
	// Structure is documented below.
	denominatorAggregations?: [...#DenominatorAggregationsObservation] @go(DenominatorAggregations,[]DenominatorAggregationsObservation)

	// A filter that identifies a time series that
	// should be used as the denominator of a ratio
	// that will be compared with the threshold. If
	// a denominator_filter is specified, the time
	// series specified by the filter field will be
	// used as the numerator.The filter is similar
	// to the one that is specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	denominatorFilter?: null | string @go(DenominatorFilter,*string)

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	duration?: null | string @go(Duration,*string)

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	evaluationMissingData?: null | string @go(EvaluationMissingData,*string)

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	filter?: null | string @go(Filter,*string)

	// When this field is present, the MetricThreshold
	// condition forecasts whether the time series is
	// predicted to violate the threshold within the
	// forecastHorizon. When this field is not set, the
	// MetricThreshold tests the current value of the
	// timeseries against the threshold.
	// Structure is documented below.
	forecastOptions?: [...#ForecastOptionsObservation] @go(ForecastOptions,[]ForecastOptionsObservation)

	// A value against which to compare the time
	// series.
	thresholdValue?: null | float64 @go(ThresholdValue,*float64)

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	trigger?: [...#ConditionThresholdTriggerObservation] @go(Trigger,[]ConditionThresholdTriggerObservation)
}

#ConditionThresholdParameters: {
	// Specifies the alignment of data points in
	// individual time series as well as how to
	// combine the retrieved time series together
	// (such as when aggregating multiple streams
	// on each resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).
	// Multiple aggregations are applied in the
	// order specified.This field is similar to the
	// one in the MetricService.ListTimeSeries
	// request. It is advisable to use the
	// ListTimeSeries method when debugging this
	// field.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	aggregations?: [...#ConditionThresholdAggregationsParameters] @go(Aggregations,[]ConditionThresholdAggregationsParameters)

	// The comparison to apply between the time
	// series (indicated by filter and aggregation)
	// and the threshold (indicated by
	// threshold_value). The comparison is applied
	// on each time series, with the time series on
	// the left-hand side and the threshold on the
	// right-hand side. Only COMPARISON_LT and
	// COMPARISON_GT are supported currently.
	// Possible values are: COMPARISON_GT, COMPARISON_GE, COMPARISON_LT, COMPARISON_LE, COMPARISON_EQ, COMPARISON_NE.
	// +kubebuilder:validation:Optional
	comparison?: null | string @go(Comparison,*string)

	// Specifies the alignment of data points in
	// individual time series selected by
	// denominatorFilter as well as how to combine
	// the retrieved time series together (such as
	// when aggregating multiple streams on each
	// resource to a single stream for each
	// resource or when aggregating streams across
	// all members of a group of resources).When
	// computing ratios, the aggregations and
	// denominator_aggregations fields must use the
	// same alignment period and produce time
	// series that have the same periodicity and
	// labels.This field is similar to the one in
	// the MetricService.ListTimeSeries request. It
	// is advisable to use the ListTimeSeries
	// method when debugging this field.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	denominatorAggregations?: [...#DenominatorAggregationsParameters] @go(DenominatorAggregations,[]DenominatorAggregationsParameters)

	// A filter that identifies a time series that
	// should be used as the denominator of a ratio
	// that will be compared with the threshold. If
	// a denominator_filter is specified, the time
	// series specified by the filter field will be
	// used as the numerator.The filter is similar
	// to the one that is specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	// +kubebuilder:validation:Optional
	denominatorFilter?: null | string @go(DenominatorFilter,*string)

	// The amount of time that a time series must
	// violate the threshold to be considered
	// failing. Currently, only values that are a
	// multiple of a minute--e.g., 0, 60, 120, or
	// 300 seconds--are supported. If an invalid
	// value is given, an error will be returned.
	// When choosing a duration, it is useful to
	// keep in mind the frequency of the underlying
	// time series data (which may also be affected
	// by any alignments specified in the
	// aggregations field); a good duration is long
	// enough so that a single outlier does not
	// generate spurious alerts, but short enough
	// that unhealthy states are detected and
	// alerted on quickly.
	// +kubebuilder:validation:Optional
	duration?: null | string @go(Duration,*string)

	// A condition control that determines how
	// metric-threshold conditions are evaluated when
	// data stops arriving.
	// Possible values are: EVALUATION_MISSING_DATA_INACTIVE, EVALUATION_MISSING_DATA_ACTIVE, EVALUATION_MISSING_DATA_NO_OP.
	// +kubebuilder:validation:Optional
	evaluationMissingData?: null | string @go(EvaluationMissingData,*string)

	// A filter that identifies which time series
	// should be compared with the threshold.The
	// filter is similar to the one that is
	// specified in the
	// MetricService.ListTimeSeries request (that
	// call is useful to verify the time series
	// that will be retrieved / processed) and must
	// specify the metric type and optionally may
	// contain restrictions on resource type,
	// resource labels, and metric labels. This
	// field may not exceed 2048 Unicode characters
	// in length.
	// +kubebuilder:validation:Optional
	filter?: null | string @go(Filter,*string)

	// When this field is present, the MetricThreshold
	// condition forecasts whether the time series is
	// predicted to violate the threshold within the
	// forecastHorizon. When this field is not set, the
	// MetricThreshold tests the current value of the
	// timeseries against the threshold.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	forecastOptions?: [...#ForecastOptionsParameters] @go(ForecastOptions,[]ForecastOptionsParameters)

	// A value against which to compare the time
	// series.
	// +kubebuilder:validation:Optional
	thresholdValue?: null | float64 @go(ThresholdValue,*float64)

	// The number/percent of time series for which
	// the comparison must hold in order for the
	// condition to trigger. If unspecified, then
	// the condition will trigger if the comparison
	// is true for any of the time series that have
	// been identified by filter and aggregations,
	// or by the ratio, if denominator_filter and
	// denominator_aggregations are specified.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	trigger?: [...#ConditionThresholdTriggerParameters] @go(Trigger,[]ConditionThresholdTriggerParameters)
}

#ConditionThresholdTriggerInitParameters: {
	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	count?: null | float64 @go(Count,*float64)

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	percent?: null | float64 @go(Percent,*float64)
}

#ConditionThresholdTriggerObservation: {
	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	count?: null | float64 @go(Count,*float64)

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	percent?: null | float64 @go(Percent,*float64)
}

#ConditionThresholdTriggerParameters: {
	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	count?: null | float64 @go(Count,*float64)

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	percent?: null | float64 @go(Percent,*float64)
}

#ConditionsInitParameters: {
	// A condition that checks that a time series
	// continues to receive new data points.
	// Structure is documented below.
	conditionAbsent?: [...#ConditionAbsentInitParameters] @go(ConditionAbsent,[]ConditionAbsentInitParameters)

	// A condition that checks for log messages matching given constraints.
	// If set, no other conditions can be present.
	// Structure is documented below.
	conditionMatchedLog?: [...#ConditionMatchedLogInitParameters] @go(ConditionMatchedLog,[]ConditionMatchedLogInitParameters)

	// A Monitoring Query Language query that outputs a boolean stream
	// Structure is documented below.
	conditionMonitoringQueryLanguage?: [...#ConditionMonitoringQueryLanguageInitParameters] @go(ConditionMonitoringQueryLanguage,[]ConditionMonitoringQueryLanguageInitParameters)

	// A Monitoring Query Language query that outputs a boolean stream
	// A condition type that allows alert policies to be defined using
	// Prometheus Query Language (PromQL).
	// The PrometheusQueryLanguageCondition message contains information
	// from a Prometheus alerting rule and its associated rule group.
	// Structure is documented below.
	conditionPrometheusQueryLanguage?: [...#ConditionPrometheusQueryLanguageInitParameters] @go(ConditionPrometheusQueryLanguage,[]ConditionPrometheusQueryLanguageInitParameters)

	// A condition that compares a time series against a
	// threshold.
	// Structure is documented below.
	conditionThreshold?: [...#ConditionThresholdInitParameters] @go(ConditionThreshold,[]ConditionThresholdInitParameters)

	// A short name or phrase used to identify the
	// condition in dashboards, notifications, and
	// incidents. To avoid confusion, don't use the same
	// display name for multiple conditions in the same
	// policy.
	displayName?: null | string @go(DisplayName,*string)
}

#ConditionsObservation: {
	// A condition that checks that a time series
	// continues to receive new data points.
	// Structure is documented below.
	conditionAbsent?: [...#ConditionAbsentObservation] @go(ConditionAbsent,[]ConditionAbsentObservation)

	// A condition that checks for log messages matching given constraints.
	// If set, no other conditions can be present.
	// Structure is documented below.
	conditionMatchedLog?: [...#ConditionMatchedLogObservation] @go(ConditionMatchedLog,[]ConditionMatchedLogObservation)

	// A Monitoring Query Language query that outputs a boolean stream
	// Structure is documented below.
	conditionMonitoringQueryLanguage?: [...#ConditionMonitoringQueryLanguageObservation] @go(ConditionMonitoringQueryLanguage,[]ConditionMonitoringQueryLanguageObservation)

	// A Monitoring Query Language query that outputs a boolean stream
	// A condition type that allows alert policies to be defined using
	// Prometheus Query Language (PromQL).
	// The PrometheusQueryLanguageCondition message contains information
	// from a Prometheus alerting rule and its associated rule group.
	// Structure is documented below.
	conditionPrometheusQueryLanguage?: [...#ConditionPrometheusQueryLanguageObservation] @go(ConditionPrometheusQueryLanguage,[]ConditionPrometheusQueryLanguageObservation)

	// A condition that compares a time series against a
	// threshold.
	// Structure is documented below.
	conditionThreshold?: [...#ConditionThresholdObservation] @go(ConditionThreshold,[]ConditionThresholdObservation)

	// A short name or phrase used to identify the
	// condition in dashboards, notifications, and
	// incidents. To avoid confusion, don't use the same
	// display name for multiple conditions in the same
	// policy.
	displayName?: null | string @go(DisplayName,*string)

	// (Output)
	// The unique resource name for this condition.
	// Its syntax is:
	// projects/[PROJECT_ID]/alertPolicies/[POLICY_ID]/conditions/[CONDITION_ID]
	// [CONDITION_ID] is assigned by Stackdriver Monitoring when
	// the condition is created as part of a new or updated alerting
	// policy.
	name?: null | string @go(Name,*string)
}

#ConditionsParameters: {
	// A condition that checks that a time series
	// continues to receive new data points.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	conditionAbsent?: [...#ConditionAbsentParameters] @go(ConditionAbsent,[]ConditionAbsentParameters)

	// A condition that checks for log messages matching given constraints.
	// If set, no other conditions can be present.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	conditionMatchedLog?: [...#ConditionMatchedLogParameters] @go(ConditionMatchedLog,[]ConditionMatchedLogParameters)

	// A Monitoring Query Language query that outputs a boolean stream
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	conditionMonitoringQueryLanguage?: [...#ConditionMonitoringQueryLanguageParameters] @go(ConditionMonitoringQueryLanguage,[]ConditionMonitoringQueryLanguageParameters)

	// A Monitoring Query Language query that outputs a boolean stream
	// A condition type that allows alert policies to be defined using
	// Prometheus Query Language (PromQL).
	// The PrometheusQueryLanguageCondition message contains information
	// from a Prometheus alerting rule and its associated rule group.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	conditionPrometheusQueryLanguage?: [...#ConditionPrometheusQueryLanguageParameters] @go(ConditionPrometheusQueryLanguage,[]ConditionPrometheusQueryLanguageParameters)

	// A condition that compares a time series against a
	// threshold.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	conditionThreshold?: [...#ConditionThresholdParameters] @go(ConditionThreshold,[]ConditionThresholdParameters)

	// A short name or phrase used to identify the
	// condition in dashboards, notifications, and
	// incidents. To avoid confusion, don't use the same
	// display name for multiple conditions in the same
	// policy.
	// +kubebuilder:validation:Optional
	displayName?: null | string @go(DisplayName,*string)
}

#CreationRecordInitParameters: {
}

#CreationRecordObservation: {
	// (Output)
	// When the change occurred.
	mutateTime?: null | string @go(MutateTime,*string)

	// (Output)
	// The email address of the user making the change.
	mutatedBy?: null | string @go(MutatedBy,*string)
}

#CreationRecordParameters: {
}

#DenominatorAggregationsInitParameters: {
	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	alignmentPeriod?: null | string @go(AlignmentPeriod,*string)

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	crossSeriesReducer?: null | string @go(CrossSeriesReducer,*string)

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	groupByFields?: [...null | string] @go(GroupByFields,[]*string)

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	perSeriesAligner?: null | string @go(PerSeriesAligner,*string)
}

#DenominatorAggregationsObservation: {
	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	alignmentPeriod?: null | string @go(AlignmentPeriod,*string)

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	crossSeriesReducer?: null | string @go(CrossSeriesReducer,*string)

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	groupByFields?: [...null | string] @go(GroupByFields,[]*string)

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	perSeriesAligner?: null | string @go(PerSeriesAligner,*string)
}

#DenominatorAggregationsParameters: {
	// The alignment period for per-time
	// series alignment. If present,
	// alignmentPeriod must be at least
	// 60 seconds. After per-time series
	// alignment, each time series will
	// contain data points only on the
	// period boundaries. If
	// perSeriesAligner is not specified
	// or equals ALIGN_NONE, then this
	// field is ignored. If
	// perSeriesAligner is specified and
	// does not equal ALIGN_NONE, then
	// this field must be defined;
	// otherwise an error is returned.
	// +kubebuilder:validation:Optional
	alignmentPeriod?: null | string @go(AlignmentPeriod,*string)

	// The approach to be used to combine
	// time series. Not all reducer
	// functions may be applied to all
	// time series, depending on the
	// metric type and the value type of
	// the original time series.
	// Reduction may change the metric
	// type of value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: REDUCE_NONE, REDUCE_MEAN, REDUCE_MIN, REDUCE_MAX, REDUCE_SUM, REDUCE_STDDEV, REDUCE_COUNT, REDUCE_COUNT_TRUE, REDUCE_COUNT_FALSE, REDUCE_FRACTION_TRUE, REDUCE_PERCENTILE_99, REDUCE_PERCENTILE_95, REDUCE_PERCENTILE_50, REDUCE_PERCENTILE_05.
	// +kubebuilder:validation:Optional
	crossSeriesReducer?: null | string @go(CrossSeriesReducer,*string)

	// The set of fields to preserve when
	// crossSeriesReducer is specified.
	// The groupByFields determine how
	// the time series are partitioned
	// into subsets prior to applying the
	// aggregation function. Each subset
	// contains time series that have the
	// same value for each of the
	// grouping fields. Each individual
	// time series is a member of exactly
	// one subset. The crossSeriesReducer
	// is applied to each subset of time
	// series. It is not possible to
	// reduce across different resource
	// types, so this field implicitly
	// contains resource.type. Fields not
	// specified in groupByFields are
	// aggregated away. If groupByFields
	// is not specified and all the time
	// series have the same resource
	// type, then the time series are
	// aggregated into a single output
	// time series. If crossSeriesReducer
	// is not defined, this field is
	// ignored.
	// +kubebuilder:validation:Optional
	groupByFields?: [...null | string] @go(GroupByFields,[]*string)

	// The approach to be used to align
	// individual time series. Not all
	// alignment functions may be applied
	// to all time series, depending on
	// the metric type and value type of
	// the original time series.
	// Alignment may change the metric
	// type or the value type of the time
	// series.Time series data must be
	// aligned in order to perform cross-
	// time series reduction. If
	// crossSeriesReducer is specified,
	// then perSeriesAligner must be
	// specified and not equal ALIGN_NONE
	// and alignmentPeriod must be
	// specified; otherwise, an error is
	// returned.
	// Possible values are: ALIGN_NONE, ALIGN_DELTA, ALIGN_RATE, ALIGN_INTERPOLATE, ALIGN_NEXT_OLDER, ALIGN_MIN, ALIGN_MAX, ALIGN_MEAN, ALIGN_COUNT, ALIGN_SUM, ALIGN_STDDEV, ALIGN_COUNT_TRUE, ALIGN_COUNT_FALSE, ALIGN_FRACTION_TRUE, ALIGN_PERCENTILE_99, ALIGN_PERCENTILE_95, ALIGN_PERCENTILE_50, ALIGN_PERCENTILE_05, ALIGN_PERCENT_CHANGE.
	// +kubebuilder:validation:Optional
	perSeriesAligner?: null | string @go(PerSeriesAligner,*string)
}

#DocumentationInitParameters: {
	// The text of the documentation, interpreted according to mimeType.
	// The content may not exceed 8,192 Unicode characters and may not
	// exceed more than 10,240 bytes when encoded in UTF-8 format,
	// whichever is smaller.
	content?: null | string @go(Content,*string)

	// The format of the content field. Presently, only the value
	// "text/markdown" is supported.
	mimeType?: null | string @go(MimeType,*string)
}

#DocumentationObservation: {
	// The text of the documentation, interpreted according to mimeType.
	// The content may not exceed 8,192 Unicode characters and may not
	// exceed more than 10,240 bytes when encoded in UTF-8 format,
	// whichever is smaller.
	content?: null | string @go(Content,*string)

	// The format of the content field. Presently, only the value
	// "text/markdown" is supported.
	mimeType?: null | string @go(MimeType,*string)
}

#DocumentationParameters: {
	// The text of the documentation, interpreted according to mimeType.
	// The content may not exceed 8,192 Unicode characters and may not
	// exceed more than 10,240 bytes when encoded in UTF-8 format,
	// whichever is smaller.
	// +kubebuilder:validation:Optional
	content?: null | string @go(Content,*string)

	// The format of the content field. Presently, only the value
	// "text/markdown" is supported.
	// +kubebuilder:validation:Optional
	mimeType?: null | string @go(MimeType,*string)
}

#ForecastOptionsInitParameters: {
	// The length of time into the future to forecast
	// whether a timeseries will violate the threshold.
	// If the predicted value is found to violate the
	// threshold, and the violation is observed in all
	// forecasts made for the Configured duration,
	// then the timeseries is considered to be failing.
	forecastHorizon?: null | string @go(ForecastHorizon,*string)
}

#ForecastOptionsObservation: {
	// The length of time into the future to forecast
	// whether a timeseries will violate the threshold.
	// If the predicted value is found to violate the
	// threshold, and the violation is observed in all
	// forecasts made for the Configured duration,
	// then the timeseries is considered to be failing.
	forecastHorizon?: null | string @go(ForecastHorizon,*string)
}

#ForecastOptionsParameters: {
	// The length of time into the future to forecast
	// whether a timeseries will violate the threshold.
	// If the predicted value is found to violate the
	// threshold, and the violation is observed in all
	// forecasts made for the Configured duration,
	// then the timeseries is considered to be failing.
	// +kubebuilder:validation:Optional
	forecastHorizon?: null | string @go(ForecastHorizon,*string)
}

#NotificationChannelStrategyInitParameters: {
	// The notification channels that these settings apply to. Each of these
	// correspond to the name field in one of the NotificationChannel objects
	// referenced in the notification_channels field of this AlertPolicy. The format is
	// projects/[PROJECT_ID_OR_NUMBER]/notificationChannels/[CHANNEL_ID]
	notificationChannelNames?: [...null | string] @go(NotificationChannelNames,[]*string)

	// The frequency at which to send reminder notifications for open incidents.
	renotifyInterval?: null | string @go(RenotifyInterval,*string)
}

#NotificationChannelStrategyObservation: {
	// The notification channels that these settings apply to. Each of these
	// correspond to the name field in one of the NotificationChannel objects
	// referenced in the notification_channels field of this AlertPolicy. The format is
	// projects/[PROJECT_ID_OR_NUMBER]/notificationChannels/[CHANNEL_ID]
	notificationChannelNames?: [...null | string] @go(NotificationChannelNames,[]*string)

	// The frequency at which to send reminder notifications for open incidents.
	renotifyInterval?: null | string @go(RenotifyInterval,*string)
}

#NotificationChannelStrategyParameters: {
	// The notification channels that these settings apply to. Each of these
	// correspond to the name field in one of the NotificationChannel objects
	// referenced in the notification_channels field of this AlertPolicy. The format is
	// projects/[PROJECT_ID_OR_NUMBER]/notificationChannels/[CHANNEL_ID]
	// +kubebuilder:validation:Optional
	notificationChannelNames?: [...null | string] @go(NotificationChannelNames,[]*string)

	// The frequency at which to send reminder notifications for open incidents.
	// +kubebuilder:validation:Optional
	renotifyInterval?: null | string @go(RenotifyInterval,*string)
}

#NotificationRateLimitInitParameters: {
	// Not more than one notification per period.
	period?: null | string @go(Period,*string)
}

#NotificationRateLimitObservation: {
	// Not more than one notification per period.
	period?: null | string @go(Period,*string)
}

#NotificationRateLimitParameters: {
	// Not more than one notification per period.
	// +kubebuilder:validation:Optional
	period?: null | string @go(Period,*string)
}

#TriggerInitParameters: {
	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	count?: null | float64 @go(Count,*float64)

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	percent?: null | float64 @go(Percent,*float64)
}

#TriggerObservation: {
	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	count?: null | float64 @go(Count,*float64)

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	percent?: null | float64 @go(Percent,*float64)
}

#TriggerParameters: {
	// The absolute number of time series
	// that must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	count?: null | float64 @go(Count,*float64)

	// The percentage of time series that
	// must fail the predicate for the
	// condition to be triggered.
	// +kubebuilder:validation:Optional
	percent?: null | float64 @go(Percent,*float64)
}

// AlertPolicySpec defines the desired state of AlertPolicy
#AlertPolicySpec: {
	forProvider: #AlertPolicyParameters @go(ForProvider)

	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	initProvider?: #AlertPolicyInitParameters @go(InitProvider)
}

// AlertPolicyStatus defines the observed state of AlertPolicy.
#AlertPolicyStatus: {
	atProvider?: #AlertPolicyObservation @go(AtProvider)
}

// AlertPolicy is the Schema for the AlertPolicys API. A description of the conditions under which some aspect of your system is considered to be "unhealthy" and the ways to notify people or services about this state.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:subresource:status
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,gcp}
#AlertPolicy: {
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.combiner) || (has(self.initProvider) && has(self.initProvider.combiner))",message="spec.forProvider.combiner is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.conditions) || (has(self.initProvider) && has(self.initProvider.conditions))",message="spec.forProvider.conditions is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.displayName) || (has(self.initProvider) && has(self.initProvider.displayName))",message="spec.forProvider.displayName is a required parameter"
	spec:    #AlertPolicySpec   @go(Spec)
	status?: #AlertPolicyStatus @go(Status)
}

// AlertPolicyList contains a list of AlertPolicys
#AlertPolicyList: {
	items: [...#AlertPolicy] @go(Items,[]AlertPolicy)
}
