// Code generated by cue get go. DO NOT EDIT.

//cue:generate cue get go github.com/upbound/provider-gcp/apis/bigquery/v1beta1

package v1beta1

#AvroOptionsInitParameters: {
	// If is set to true, indicates whether
	// to interpret logical types as the corresponding BigQuery data type
	// (for example, TIMESTAMP), instead of using the raw type (for example, INTEGER).
	useAvroLogicalTypes?: null | bool @go(UseAvroLogicalTypes,*bool)
}

#AvroOptionsObservation: {
	// If is set to true, indicates whether
	// to interpret logical types as the corresponding BigQuery data type
	// (for example, TIMESTAMP), instead of using the raw type (for example, INTEGER).
	useAvroLogicalTypes?: null | bool @go(UseAvroLogicalTypes,*bool)
}

#AvroOptionsParameters: {
	// If is set to true, indicates whether
	// to interpret logical types as the corresponding BigQuery data type
	// (for example, TIMESTAMP), instead of using the raw type (for example, INTEGER).
	// +kubebuilder:validation:Optional
	useAvroLogicalTypes?: null | bool @go(UseAvroLogicalTypes,*bool)
}

#CsvOptionsInitParameters: {
	// Indicates if BigQuery should accept rows
	// that are missing trailing optional columns.
	allowJaggedRows?: null | bool @go(AllowJaggedRows,*bool)

	// Indicates if BigQuery should allow
	// quoted data sections that contain newline characters in a CSV file.
	// The default value is false.
	allowQuotedNewlines?: null | bool @go(AllowQuotedNewlines,*bool)

	// The character encoding of the data. The supported
	// values are UTF-8 or ISO-8859-1.
	encoding?: null | string @go(Encoding,*string)

	// The separator for fields in a CSV file.
	fieldDelimiter?: null | string @go(FieldDelimiter,*string)

	// The value that is used to quote data sections in a
	// CSV file. If your data does not contain quoted sections, set the
	// property value to an empty string. If your data contains quoted newline
	// characters, you must also set the allow_quoted_newlines property to true.
	quote?: null | string @go(Quote,*string)

	// The number of rows at the top of the sheet
	// that BigQuery will skip when reading the data. At least one of range or
	// skip_leading_rows must be set.
	skipLeadingRows?: null | float64 @go(SkipLeadingRows,*float64)
}

#CsvOptionsObservation: {
	// Indicates if BigQuery should accept rows
	// that are missing trailing optional columns.
	allowJaggedRows?: null | bool @go(AllowJaggedRows,*bool)

	// Indicates if BigQuery should allow
	// quoted data sections that contain newline characters in a CSV file.
	// The default value is false.
	allowQuotedNewlines?: null | bool @go(AllowQuotedNewlines,*bool)

	// The character encoding of the data. The supported
	// values are UTF-8 or ISO-8859-1.
	encoding?: null | string @go(Encoding,*string)

	// The separator for fields in a CSV file.
	fieldDelimiter?: null | string @go(FieldDelimiter,*string)

	// The value that is used to quote data sections in a
	// CSV file. If your data does not contain quoted sections, set the
	// property value to an empty string. If your data contains quoted newline
	// characters, you must also set the allow_quoted_newlines property to true.
	quote?: null | string @go(Quote,*string)

	// The number of rows at the top of the sheet
	// that BigQuery will skip when reading the data. At least one of range or
	// skip_leading_rows must be set.
	skipLeadingRows?: null | float64 @go(SkipLeadingRows,*float64)
}

#CsvOptionsParameters: {
	// Indicates if BigQuery should accept rows
	// that are missing trailing optional columns.
	// +kubebuilder:validation:Optional
	allowJaggedRows?: null | bool @go(AllowJaggedRows,*bool)

	// Indicates if BigQuery should allow
	// quoted data sections that contain newline characters in a CSV file.
	// The default value is false.
	// +kubebuilder:validation:Optional
	allowQuotedNewlines?: null | bool @go(AllowQuotedNewlines,*bool)

	// The character encoding of the data. The supported
	// values are UTF-8 or ISO-8859-1.
	// +kubebuilder:validation:Optional
	encoding?: null | string @go(Encoding,*string)

	// The separator for fields in a CSV file.
	// +kubebuilder:validation:Optional
	fieldDelimiter?: null | string @go(FieldDelimiter,*string)

	// The value that is used to quote data sections in a
	// CSV file. If your data does not contain quoted sections, set the
	// property value to an empty string. If your data contains quoted newline
	// characters, you must also set the allow_quoted_newlines property to true.
	// +kubebuilder:validation:Optional
	quote?: null | string @go(Quote,*string)

	// The number of rows at the top of the sheet
	// that BigQuery will skip when reading the data. At least one of range or
	// skip_leading_rows must be set.
	// +kubebuilder:validation:Optional
	skipLeadingRows?: null | float64 @go(SkipLeadingRows,*float64)
}

#EncryptionConfigurationInitParameters: {
	// The self link or full name of a key which should be used to
	// encrypt this table.  Note that the default bigquery service account will need to have
	// encrypt/decrypt permissions on this key - you may want to see the
	// google_bigquery_default_service_account datasource and the
	// google_kms_crypto_key_iam_binding resource.
	kmsKeyName?: null | string @go(KMSKeyName,*string)
}

#EncryptionConfigurationObservation: {
	// The self link or full name of a key which should be used to
	// encrypt this table.  Note that the default bigquery service account will need to have
	// encrypt/decrypt permissions on this key - you may want to see the
	// google_bigquery_default_service_account datasource and the
	// google_kms_crypto_key_iam_binding resource.
	kmsKeyName?: null | string @go(KMSKeyName,*string)

	// The self link or full name of the kms key version used to encrypt this table.
	kmsKeyVersion?: null | string @go(KMSKeyVersion,*string)
}

#EncryptionConfigurationParameters: {
	// The self link or full name of a key which should be used to
	// encrypt this table.  Note that the default bigquery service account will need to have
	// encrypt/decrypt permissions on this key - you may want to see the
	// google_bigquery_default_service_account datasource and the
	// google_kms_crypto_key_iam_binding resource.
	// +kubebuilder:validation:Optional
	kmsKeyName?: null | string @go(KMSKeyName,*string)
}

#ExternalDataConfigurationInitParameters: {
	// - Let BigQuery try to autodetect the schema
	// and format of the table.
	autodetect?: null | bool @go(Autodetect,*bool)

	// Additional options if source_format is set to
	// "AVRO".  Structure is documented below.
	avroOptions?: [...#AvroOptionsInitParameters] @go(AvroOptions,[]AvroOptionsInitParameters)

	// The compression type of the data source.
	// Valid values are "NONE" or "GZIP".
	compression?: null | string @go(Compression,*string)

	// The connection specifying the credentials to be used to read
	// external storage, such as Azure Blob, Cloud Storage, or S3. The connection_id can have
	// the form {{project}}.{{location}}.{{connection_id}}
	// or projects/{{project}}/locations/{{location}}/connections/{{connection_id}}.
	connectionId?: null | string @go(ConnectionID,*string)

	// Additional properties to set if
	// source_format is set to "CSV". Structure is documented below.
	csvOptions?: [...#CsvOptionsInitParameters] @go(CsvOptions,[]CsvOptionsInitParameters)

	// Additional options if
	// source_format is set to "GOOGLE_SHEETS". Structure is
	// documented below.
	googleSheetsOptions?: [...#GoogleSheetsOptionsInitParameters] @go(GoogleSheetsOptions,[]GoogleSheetsOptionsInitParameters)

	// When set, configures hive partitioning
	// support. Not all storage formats support hive partitioning -- requesting hive
	// partitioning on an unsupported format will lead to an error, as will providing
	// an invalid specification. Structure is documented below.
	hivePartitioningOptions?: [...#HivePartitioningOptionsInitParameters] @go(HivePartitioningOptions,[]HivePartitioningOptionsInitParameters)

	// Indicates if BigQuery should
	// allow extra values that are not represented in the table schema.
	// If true, the extra values are ignored. If false, records with
	// extra columns are treated as bad records, and if there are too
	// many bad records, an invalid error is returned in the job result.
	// The default value is false.
	ignoreUnknownValues?: null | bool @go(IgnoreUnknownValues,*bool)

	// The maximum number of bad records that
	// BigQuery can ignore when reading data.
	maxBadRecords?: null | float64 @go(MaxBadRecords,*float64)

	// When creating an external table, the user can provide a reference file with the table schema. This is enabled for the following formats: AVRO, PARQUET, ORC.
	referenceFileSchemaUri?: null | string @go(ReferenceFileSchemaURI,*string)

	// A JSON schema for the external table. Schema is required
	// for CSV and JSON formats if autodetect is not on. Schema is disallowed
	// for Google Cloud Bigtable, Cloud Datastore backups, Avro, Iceberg, ORC and Parquet formats.
	// ~>NOTE: Because this field expects a JSON string, any changes to the
	// string will create a diff, even if the JSON itself hasn't changed.
	// Furthermore drift for this field cannot not be detected because BigQuery
	// only uses this schema to compute the effective schema for the table, therefore
	// any changes on the configured value will force the table to be recreated.
	// This schema is effectively only applied when creating a table from an external
	// datasource, after creation the computed schema will be stored in
	// google_bigquery_table.schema
	schema?: null | string @go(Schema,*string)

	// The data format. Please see sourceFormat under
	// ExternalDataConfiguration
	// in Bigquery's public API documentation for supported formats. To use "GOOGLE_SHEETS"
	// the scopes must include "https://www.googleapis.com/auth/drive.readonly".
	sourceFormat?: null | string @go(SourceFormat,*string)

	// A list of the fully-qualified URIs that point to
	// your data in Google Cloud.
	sourceUris?: [...null | string] @go(SourceUris,[]*string)
}

#ExternalDataConfigurationObservation: {
	// - Let BigQuery try to autodetect the schema
	// and format of the table.
	autodetect?: null | bool @go(Autodetect,*bool)

	// Additional options if source_format is set to
	// "AVRO".  Structure is documented below.
	avroOptions?: [...#AvroOptionsObservation] @go(AvroOptions,[]AvroOptionsObservation)

	// The compression type of the data source.
	// Valid values are "NONE" or "GZIP".
	compression?: null | string @go(Compression,*string)

	// The connection specifying the credentials to be used to read
	// external storage, such as Azure Blob, Cloud Storage, or S3. The connection_id can have
	// the form {{project}}.{{location}}.{{connection_id}}
	// or projects/{{project}}/locations/{{location}}/connections/{{connection_id}}.
	connectionId?: null | string @go(ConnectionID,*string)

	// Additional properties to set if
	// source_format is set to "CSV". Structure is documented below.
	csvOptions?: [...#CsvOptionsObservation] @go(CsvOptions,[]CsvOptionsObservation)

	// Additional options if
	// source_format is set to "GOOGLE_SHEETS". Structure is
	// documented below.
	googleSheetsOptions?: [...#GoogleSheetsOptionsObservation] @go(GoogleSheetsOptions,[]GoogleSheetsOptionsObservation)

	// When set, configures hive partitioning
	// support. Not all storage formats support hive partitioning -- requesting hive
	// partitioning on an unsupported format will lead to an error, as will providing
	// an invalid specification. Structure is documented below.
	hivePartitioningOptions?: [...#HivePartitioningOptionsObservation] @go(HivePartitioningOptions,[]HivePartitioningOptionsObservation)

	// Indicates if BigQuery should
	// allow extra values that are not represented in the table schema.
	// If true, the extra values are ignored. If false, records with
	// extra columns are treated as bad records, and if there are too
	// many bad records, an invalid error is returned in the job result.
	// The default value is false.
	ignoreUnknownValues?: null | bool @go(IgnoreUnknownValues,*bool)

	// The maximum number of bad records that
	// BigQuery can ignore when reading data.
	maxBadRecords?: null | float64 @go(MaxBadRecords,*float64)

	// When creating an external table, the user can provide a reference file with the table schema. This is enabled for the following formats: AVRO, PARQUET, ORC.
	referenceFileSchemaUri?: null | string @go(ReferenceFileSchemaURI,*string)

	// A JSON schema for the external table. Schema is required
	// for CSV and JSON formats if autodetect is not on. Schema is disallowed
	// for Google Cloud Bigtable, Cloud Datastore backups, Avro, Iceberg, ORC and Parquet formats.
	// ~>NOTE: Because this field expects a JSON string, any changes to the
	// string will create a diff, even if the JSON itself hasn't changed.
	// Furthermore drift for this field cannot not be detected because BigQuery
	// only uses this schema to compute the effective schema for the table, therefore
	// any changes on the configured value will force the table to be recreated.
	// This schema is effectively only applied when creating a table from an external
	// datasource, after creation the computed schema will be stored in
	// google_bigquery_table.schema
	schema?: null | string @go(Schema,*string)

	// The data format. Please see sourceFormat under
	// ExternalDataConfiguration
	// in Bigquery's public API documentation for supported formats. To use "GOOGLE_SHEETS"
	// the scopes must include "https://www.googleapis.com/auth/drive.readonly".
	sourceFormat?: null | string @go(SourceFormat,*string)

	// A list of the fully-qualified URIs that point to
	// your data in Google Cloud.
	sourceUris?: [...null | string] @go(SourceUris,[]*string)
}

#ExternalDataConfigurationParameters: {
	// - Let BigQuery try to autodetect the schema
	// and format of the table.
	// +kubebuilder:validation:Optional
	autodetect?: null | bool @go(Autodetect,*bool)

	// Additional options if source_format is set to
	// "AVRO".  Structure is documented below.
	// +kubebuilder:validation:Optional
	avroOptions?: [...#AvroOptionsParameters] @go(AvroOptions,[]AvroOptionsParameters)

	// The compression type of the data source.
	// Valid values are "NONE" or "GZIP".
	// +kubebuilder:validation:Optional
	compression?: null | string @go(Compression,*string)

	// The connection specifying the credentials to be used to read
	// external storage, such as Azure Blob, Cloud Storage, or S3. The connection_id can have
	// the form {{project}}.{{location}}.{{connection_id}}
	// or projects/{{project}}/locations/{{location}}/connections/{{connection_id}}.
	// +kubebuilder:validation:Optional
	connectionId?: null | string @go(ConnectionID,*string)

	// Additional properties to set if
	// source_format is set to "CSV". Structure is documented below.
	// +kubebuilder:validation:Optional
	csvOptions?: [...#CsvOptionsParameters] @go(CsvOptions,[]CsvOptionsParameters)

	// Additional options if
	// source_format is set to "GOOGLE_SHEETS". Structure is
	// documented below.
	// +kubebuilder:validation:Optional
	googleSheetsOptions?: [...#GoogleSheetsOptionsParameters] @go(GoogleSheetsOptions,[]GoogleSheetsOptionsParameters)

	// When set, configures hive partitioning
	// support. Not all storage formats support hive partitioning -- requesting hive
	// partitioning on an unsupported format will lead to an error, as will providing
	// an invalid specification. Structure is documented below.
	// +kubebuilder:validation:Optional
	hivePartitioningOptions?: [...#HivePartitioningOptionsParameters] @go(HivePartitioningOptions,[]HivePartitioningOptionsParameters)

	// Indicates if BigQuery should
	// allow extra values that are not represented in the table schema.
	// If true, the extra values are ignored. If false, records with
	// extra columns are treated as bad records, and if there are too
	// many bad records, an invalid error is returned in the job result.
	// The default value is false.
	// +kubebuilder:validation:Optional
	ignoreUnknownValues?: null | bool @go(IgnoreUnknownValues,*bool)

	// The maximum number of bad records that
	// BigQuery can ignore when reading data.
	// +kubebuilder:validation:Optional
	maxBadRecords?: null | float64 @go(MaxBadRecords,*float64)

	// When creating an external table, the user can provide a reference file with the table schema. This is enabled for the following formats: AVRO, PARQUET, ORC.
	// +kubebuilder:validation:Optional
	referenceFileSchemaUri?: null | string @go(ReferenceFileSchemaURI,*string)

	// A JSON schema for the external table. Schema is required
	// for CSV and JSON formats if autodetect is not on. Schema is disallowed
	// for Google Cloud Bigtable, Cloud Datastore backups, Avro, Iceberg, ORC and Parquet formats.
	// ~>NOTE: Because this field expects a JSON string, any changes to the
	// string will create a diff, even if the JSON itself hasn't changed.
	// Furthermore drift for this field cannot not be detected because BigQuery
	// only uses this schema to compute the effective schema for the table, therefore
	// any changes on the configured value will force the table to be recreated.
	// This schema is effectively only applied when creating a table from an external
	// datasource, after creation the computed schema will be stored in
	// google_bigquery_table.schema
	// +kubebuilder:validation:Optional
	schema?: null | string @go(Schema,*string)

	// The data format. Please see sourceFormat under
	// ExternalDataConfiguration
	// in Bigquery's public API documentation for supported formats. To use "GOOGLE_SHEETS"
	// the scopes must include "https://www.googleapis.com/auth/drive.readonly".
	// +kubebuilder:validation:Optional
	sourceFormat?: null | string @go(SourceFormat,*string)

	// A list of the fully-qualified URIs that point to
	// your data in Google Cloud.
	// +kubebuilder:validation:Optional
	sourceUris?: [...null | string] @go(SourceUris,[]*string)
}

#GoogleSheetsOptionsInitParameters: {
	// Information required to partition based on ranges.
	// Structure is documented below.
	range?: null | string @go(Range,*string)

	// The number of rows at the top of the sheet
	// that BigQuery will skip when reading the data. At least one of range or
	// skip_leading_rows must be set.
	skipLeadingRows?: null | float64 @go(SkipLeadingRows,*float64)
}

#GoogleSheetsOptionsObservation: {
	// Information required to partition based on ranges.
	// Structure is documented below.
	range?: null | string @go(Range,*string)

	// The number of rows at the top of the sheet
	// that BigQuery will skip when reading the data. At least one of range or
	// skip_leading_rows must be set.
	skipLeadingRows?: null | float64 @go(SkipLeadingRows,*float64)
}

#GoogleSheetsOptionsParameters: {
	// Information required to partition based on ranges.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	range?: null | string @go(Range,*string)

	// The number of rows at the top of the sheet
	// that BigQuery will skip when reading the data. At least one of range or
	// skip_leading_rows must be set.
	// +kubebuilder:validation:Optional
	skipLeadingRows?: null | float64 @go(SkipLeadingRows,*float64)
}

#HivePartitioningOptionsInitParameters: {
	// When set, what mode of hive partitioning to use when
	// reading data. The following modes are supported.
	mode?: null | string @go(Mode,*string)

	// If set to true, queries over this table
	// require a partition filter that can be used for partition elimination to be
	// specified.
	requirePartitionFilter?: null | bool @go(RequirePartitionFilter,*bool)

	// When hive partition detection is requested,
	// a common for all source uris must be required. The prefix must end immediately
	// before the partition key encoding begins. For example, consider files following
	// this data layout. gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro
	// gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro When hive
	// partitioning is requested with either AUTO or STRINGS detection, the common prefix
	// can be either of gs://bucket/path_to_table or gs://bucket/path_to_table/.
	// Note that when mode is set to CUSTOM, you must encode the partition key schema within the source_uri_prefix by setting source_uri_prefix to gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}.
	sourceUriPrefix?: null | string @go(SourceURIPrefix,*string)
}

#HivePartitioningOptionsObservation: {
	// When set, what mode of hive partitioning to use when
	// reading data. The following modes are supported.
	mode?: null | string @go(Mode,*string)

	// If set to true, queries over this table
	// require a partition filter that can be used for partition elimination to be
	// specified.
	requirePartitionFilter?: null | bool @go(RequirePartitionFilter,*bool)

	// When hive partition detection is requested,
	// a common for all source uris must be required. The prefix must end immediately
	// before the partition key encoding begins. For example, consider files following
	// this data layout. gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro
	// gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro When hive
	// partitioning is requested with either AUTO or STRINGS detection, the common prefix
	// can be either of gs://bucket/path_to_table or gs://bucket/path_to_table/.
	// Note that when mode is set to CUSTOM, you must encode the partition key schema within the source_uri_prefix by setting source_uri_prefix to gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}.
	sourceUriPrefix?: null | string @go(SourceURIPrefix,*string)
}

#HivePartitioningOptionsParameters: {
	// When set, what mode of hive partitioning to use when
	// reading data. The following modes are supported.
	// +kubebuilder:validation:Optional
	mode?: null | string @go(Mode,*string)

	// If set to true, queries over this table
	// require a partition filter that can be used for partition elimination to be
	// specified.
	// +kubebuilder:validation:Optional
	requirePartitionFilter?: null | bool @go(RequirePartitionFilter,*bool)

	// When hive partition detection is requested,
	// a common for all source uris must be required. The prefix must end immediately
	// before the partition key encoding begins. For example, consider files following
	// this data layout. gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro
	// gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro When hive
	// partitioning is requested with either AUTO or STRINGS detection, the common prefix
	// can be either of gs://bucket/path_to_table or gs://bucket/path_to_table/.
	// Note that when mode is set to CUSTOM, you must encode the partition key schema within the source_uri_prefix by setting source_uri_prefix to gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}.
	// +kubebuilder:validation:Optional
	sourceUriPrefix?: null | string @go(SourceURIPrefix,*string)
}

#MaterializedViewInitParameters: {
	// Specifies whether to use BigQuery's automatic refresh for this materialized view when the base table is updated.
	// The default value is true.
	enableRefresh?: null | bool @go(EnableRefresh,*bool)

	// A query whose result is persisted.
	query?: null | string @go(Query,*string)

	// The maximum frequency at which this materialized view will be refreshed.
	// The default value is 1800000
	refreshIntervalMs?: null | float64 @go(RefreshIntervalMs,*float64)
}

#MaterializedViewObservation: {
	// Specifies whether to use BigQuery's automatic refresh for this materialized view when the base table is updated.
	// The default value is true.
	enableRefresh?: null | bool @go(EnableRefresh,*bool)

	// A query whose result is persisted.
	query?: null | string @go(Query,*string)

	// The maximum frequency at which this materialized view will be refreshed.
	// The default value is 1800000
	refreshIntervalMs?: null | float64 @go(RefreshIntervalMs,*float64)
}

#MaterializedViewParameters: {
	// Specifies whether to use BigQuery's automatic refresh for this materialized view when the base table is updated.
	// The default value is true.
	// +kubebuilder:validation:Optional
	enableRefresh?: null | bool @go(EnableRefresh,*bool)

	// A query whose result is persisted.
	// +kubebuilder:validation:Optional
	query?: null | string @go(Query,*string)

	// The maximum frequency at which this materialized view will be refreshed.
	// The default value is 1800000
	// +kubebuilder:validation:Optional
	refreshIntervalMs?: null | float64 @go(RefreshIntervalMs,*float64)
}

#RangeInitParameters: {
	// End of the range partitioning, exclusive.
	end?: null | float64 @go(End,*float64)

	// The width of each range within the partition.
	interval?: null | float64 @go(Interval,*float64)

	// Start of the range partitioning, inclusive.
	start?: null | float64 @go(Start,*float64)
}

#RangeObservation: {
	// End of the range partitioning, exclusive.
	end?: null | float64 @go(End,*float64)

	// The width of each range within the partition.
	interval?: null | float64 @go(Interval,*float64)

	// Start of the range partitioning, inclusive.
	start?: null | float64 @go(Start,*float64)
}

#RangeParameters: {
	// End of the range partitioning, exclusive.
	// +kubebuilder:validation:Optional
	end?: null | float64 @go(End,*float64)

	// The width of each range within the partition.
	// +kubebuilder:validation:Optional
	interval?: null | float64 @go(Interval,*float64)

	// Start of the range partitioning, inclusive.
	// +kubebuilder:validation:Optional
	start?: null | float64 @go(Start,*float64)
}

#RangePartitioningInitParameters: {
	// The field used to determine how to create a range-based
	// partition.
	field?: null | string @go(Field,*string)

	// Information required to partition based on ranges.
	// Structure is documented below.
	range?: [...#RangeInitParameters] @go(Range,[]RangeInitParameters)
}

#RangePartitioningObservation: {
	// The field used to determine how to create a range-based
	// partition.
	field?: null | string @go(Field,*string)

	// Information required to partition based on ranges.
	// Structure is documented below.
	range?: [...#RangeObservation] @go(Range,[]RangeObservation)
}

#RangePartitioningParameters: {
	// The field used to determine how to create a range-based
	// partition.
	// +kubebuilder:validation:Optional
	field?: null | string @go(Field,*string)

	// Information required to partition based on ranges.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	range?: [...#RangeParameters] @go(Range,[]RangeParameters)
}

#TableInitParameters: {
	// Specifies column names to use for data clustering.
	// Up to four top-level columns are allowed, and should be specified in
	// descending priority order.
	clustering?: [...null | string] @go(Clustering,[]*string)
	deletionProtection?: null | bool @go(DeletionProtection,*bool)

	// The field description.
	description?: null | string @go(Description,*string)

	// Specifies how the table should be encrypted.
	// If left blank, the table will be encrypted with a Google-managed key; that process
	// is transparent to the user.  Structure is documented below.
	encryptionConfiguration?: [...#EncryptionConfigurationInitParameters] @go(EncryptionConfiguration,[]EncryptionConfigurationInitParameters)

	// The time when this table expires, in
	// milliseconds since the epoch. If not present, the table will persist
	// indefinitely. Expired tables will be deleted and their storage
	// reclaimed.
	expirationTime?: null | float64 @go(ExpirationTime,*float64)

	// Describes the data format,
	// location, and other properties of a table stored outside of BigQuery.
	// By defining these properties, the data source can then be queried as
	// if it were a standard BigQuery table. Structure is documented below.
	externalDataConfiguration?: [...#ExternalDataConfigurationInitParameters] @go(ExternalDataConfiguration,[]ExternalDataConfigurationInitParameters)

	// A descriptive name for the table.
	friendlyName?: null | string @go(FriendlyName,*string)

	// A mapping of labels to assign to the resource.
	labels?: {[string]: null | string} @go(Labels,map[string]*string)

	// If specified, configures this table as a materialized view.
	// Structure is documented below.
	materializedView?: [...#MaterializedViewInitParameters] @go(MaterializedView,[]MaterializedViewInitParameters)

	// If specified, configures range-based
	// partitioning for this table. Structure is documented below.
	rangePartitioning?: [...#RangePartitioningInitParameters] @go(RangePartitioning,[]RangePartitioningInitParameters)

	// A JSON schema for the table.
	schema?: null | string @go(Schema,*string)

	// If specified, configures time-based
	// partitioning for this table. Structure is documented below.
	timePartitioning?: [...#TableTimePartitioningInitParameters] @go(TimePartitioning,[]TableTimePartitioningInitParameters)

	// If specified, configures this table as a view.
	// Structure is documented below.
	view?: [...#TableViewInitParameters] @go(View,[]TableViewInitParameters)
}

#TableObservation: {
	// Specifies column names to use for data clustering.
	// Up to four top-level columns are allowed, and should be specified in
	// descending priority order.
	clustering?: [...null | string] @go(Clustering,[]*string)

	// The time when this table was created, in milliseconds since the epoch.
	creationTime?: null | float64 @go(CreationTime,*float64)

	// The dataset ID to create the table in.
	// Changing this forces a new resource to be created.
	datasetId?:          null | string @go(DatasetID,*string)
	deletionProtection?: null | bool   @go(DeletionProtection,*bool)

	// The field description.
	description?: null | string @go(Description,*string)

	// Specifies how the table should be encrypted.
	// If left blank, the table will be encrypted with a Google-managed key; that process
	// is transparent to the user.  Structure is documented below.
	encryptionConfiguration?: [...#EncryptionConfigurationObservation] @go(EncryptionConfiguration,[]EncryptionConfigurationObservation)

	// A hash of the resource.
	etag?: null | string @go(Etag,*string)

	// The time when this table expires, in
	// milliseconds since the epoch. If not present, the table will persist
	// indefinitely. Expired tables will be deleted and their storage
	// reclaimed.
	expirationTime?: null | float64 @go(ExpirationTime,*float64)

	// Describes the data format,
	// location, and other properties of a table stored outside of BigQuery.
	// By defining these properties, the data source can then be queried as
	// if it were a standard BigQuery table. Structure is documented below.
	externalDataConfiguration?: [...#ExternalDataConfigurationObservation] @go(ExternalDataConfiguration,[]ExternalDataConfigurationObservation)

	// A descriptive name for the table.
	friendlyName?: null | string @go(FriendlyName,*string)

	// an identifier for the resource with format projects/{{project}}/datasets/{{dataset}}/tables/{{name}}
	id?: null | string @go(ID,*string)

	// A mapping of labels to assign to the resource.
	labels?: {[string]: null | string} @go(Labels,map[string]*string)

	// The time when this table was last modified, in milliseconds since the epoch.
	lastModifiedTime?: null | float64 @go(LastModifiedTime,*float64)

	// The geographic location where the table resides. This value is inherited from the dataset.
	location?: null | string @go(Location,*string)

	// If specified, configures this table as a materialized view.
	// Structure is documented below.
	materializedView?: [...#MaterializedViewObservation] @go(MaterializedView,[]MaterializedViewObservation)

	// The size of this table in bytes, excluding any data in the streaming buffer.
	numBytes?: null | float64 @go(NumBytes,*float64)

	// The number of bytes in the table that are considered "long-term storage".
	numLongTermBytes?: null | float64 @go(NumLongTermBytes,*float64)

	// The number of rows of data in this table, excluding any data in the streaming buffer.
	numRows?: null | float64 @go(NumRows,*float64)

	// The ID of the project in which the resource belongs. If it
	// is not provided, the provider project is used.
	project?: null | string @go(Project,*string)

	// If specified, configures range-based
	// partitioning for this table. Structure is documented below.
	rangePartitioning?: [...#RangePartitioningObservation] @go(RangePartitioning,[]RangePartitioningObservation)

	// A JSON schema for the table.
	schema?: null | string @go(Schema,*string)

	// The URI of the created resource.
	selfLink?: null | string @go(SelfLink,*string)

	// If specified, configures time-based
	// partitioning for this table. Structure is documented below.
	timePartitioning?: [...#TableTimePartitioningObservation] @go(TimePartitioning,[]TableTimePartitioningObservation)

	// Describes the table type.
	type?: null | string @go(Type,*string)

	// If specified, configures this table as a view.
	// Structure is documented below.
	view?: [...#TableViewObservation] @go(View,[]TableViewObservation)
}

#TableParameters: {
	// Specifies column names to use for data clustering.
	// Up to four top-level columns are allowed, and should be specified in
	// descending priority order.
	// +kubebuilder:validation:Optional
	clustering?: [...null | string] @go(Clustering,[]*string)

	// The dataset ID to create the table in.
	// Changing this forces a new resource to be created.
	// +crossplane:generate:reference:type=github.com/upbound/provider-gcp/apis/bigquery/v1beta1.Dataset
	// +kubebuilder:validation:Optional
	datasetId?: null | string @go(DatasetID,*string)

	// +kubebuilder:validation:Optional
	deletionProtection?: null | bool @go(DeletionProtection,*bool)

	// The field description.
	// +kubebuilder:validation:Optional
	description?: null | string @go(Description,*string)

	// Specifies how the table should be encrypted.
	// If left blank, the table will be encrypted with a Google-managed key; that process
	// is transparent to the user.  Structure is documented below.
	// +kubebuilder:validation:Optional
	encryptionConfiguration?: [...#EncryptionConfigurationParameters] @go(EncryptionConfiguration,[]EncryptionConfigurationParameters)

	// The time when this table expires, in
	// milliseconds since the epoch. If not present, the table will persist
	// indefinitely. Expired tables will be deleted and their storage
	// reclaimed.
	// +kubebuilder:validation:Optional
	expirationTime?: null | float64 @go(ExpirationTime,*float64)

	// Describes the data format,
	// location, and other properties of a table stored outside of BigQuery.
	// By defining these properties, the data source can then be queried as
	// if it were a standard BigQuery table. Structure is documented below.
	// +kubebuilder:validation:Optional
	externalDataConfiguration?: [...#ExternalDataConfigurationParameters] @go(ExternalDataConfiguration,[]ExternalDataConfigurationParameters)

	// A descriptive name for the table.
	// +kubebuilder:validation:Optional
	friendlyName?: null | string @go(FriendlyName,*string)

	// A mapping of labels to assign to the resource.
	// +kubebuilder:validation:Optional
	labels?: {[string]: null | string} @go(Labels,map[string]*string)

	// If specified, configures this table as a materialized view.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	materializedView?: [...#MaterializedViewParameters] @go(MaterializedView,[]MaterializedViewParameters)

	// The ID of the project in which the resource belongs. If it
	// is not provided, the provider project is used.
	// +kubebuilder:validation:Optional
	project?: null | string @go(Project,*string)

	// If specified, configures range-based
	// partitioning for this table. Structure is documented below.
	// +kubebuilder:validation:Optional
	rangePartitioning?: [...#RangePartitioningParameters] @go(RangePartitioning,[]RangePartitioningParameters)

	// A JSON schema for the table.
	// +kubebuilder:validation:Optional
	schema?: null | string @go(Schema,*string)

	// If specified, configures time-based
	// partitioning for this table. Structure is documented below.
	// +kubebuilder:validation:Optional
	timePartitioning?: [...#TableTimePartitioningParameters] @go(TimePartitioning,[]TableTimePartitioningParameters)

	// If specified, configures this table as a view.
	// Structure is documented below.
	// +kubebuilder:validation:Optional
	view?: [...#TableViewParameters] @go(View,[]TableViewParameters)
}

#TableTimePartitioningInitParameters: {
	// Number of milliseconds for which to keep the
	// storage for a partition.
	expirationMs?: null | float64 @go(ExpirationMs,*float64)

	// The field used to determine how to create a time-based
	// partition. If time-based partitioning is enabled without this value, the
	// table is partitioned based on the load time.
	field?: null | string @go(Field,*string)

	// If set to true, queries over this table
	// require a partition filter that can be used for partition elimination to be
	// specified.
	requirePartitionFilter?: null | bool @go(RequirePartitionFilter,*bool)

	// The supported types are DAY, HOUR, MONTH, and YEAR,
	// which will generate one partition per day, hour, month, and year, respectively.
	type?: null | string @go(Type,*string)
}

#TableTimePartitioningObservation: {
	// Number of milliseconds for which to keep the
	// storage for a partition.
	expirationMs?: null | float64 @go(ExpirationMs,*float64)

	// The field used to determine how to create a time-based
	// partition. If time-based partitioning is enabled without this value, the
	// table is partitioned based on the load time.
	field?: null | string @go(Field,*string)

	// If set to true, queries over this table
	// require a partition filter that can be used for partition elimination to be
	// specified.
	requirePartitionFilter?: null | bool @go(RequirePartitionFilter,*bool)

	// The supported types are DAY, HOUR, MONTH, and YEAR,
	// which will generate one partition per day, hour, month, and year, respectively.
	type?: null | string @go(Type,*string)
}

#TableTimePartitioningParameters: {
	// Number of milliseconds for which to keep the
	// storage for a partition.
	// +kubebuilder:validation:Optional
	expirationMs?: null | float64 @go(ExpirationMs,*float64)

	// The field used to determine how to create a time-based
	// partition. If time-based partitioning is enabled without this value, the
	// table is partitioned based on the load time.
	// +kubebuilder:validation:Optional
	field?: null | string @go(Field,*string)

	// If set to true, queries over this table
	// require a partition filter that can be used for partition elimination to be
	// specified.
	// +kubebuilder:validation:Optional
	requirePartitionFilter?: null | bool @go(RequirePartitionFilter,*bool)

	// The supported types are DAY, HOUR, MONTH, and YEAR,
	// which will generate one partition per day, hour, month, and year, respectively.
	// +kubebuilder:validation:Optional
	type?: null | string @go(Type,*string)
}

#TableViewInitParameters: {
	// A query that BigQuery executes when the view is referenced.
	query?: null | string @go(Query,*string)

	// Specifies whether to use BigQuery's legacy SQL for this view.
	// The default value is true. If set to false, the view will use BigQuery's standard SQL.
	useLegacySql?: null | bool @go(UseLegacySQL,*bool)
}

#TableViewObservation: {
	// A query that BigQuery executes when the view is referenced.
	query?: null | string @go(Query,*string)

	// Specifies whether to use BigQuery's legacy SQL for this view.
	// The default value is true. If set to false, the view will use BigQuery's standard SQL.
	useLegacySql?: null | bool @go(UseLegacySQL,*bool)
}

#TableViewParameters: {
	// A query that BigQuery executes when the view is referenced.
	// +kubebuilder:validation:Optional
	query?: null | string @go(Query,*string)

	// Specifies whether to use BigQuery's legacy SQL for this view.
	// The default value is true. If set to false, the view will use BigQuery's standard SQL.
	// +kubebuilder:validation:Optional
	useLegacySql?: null | bool @go(UseLegacySQL,*bool)
}

// TableSpec defines the desired state of Table
#TableSpec: {
	forProvider: #TableParameters @go(ForProvider)

	// THIS IS AN ALPHA FIELD. Do not use it in production. It is not honored
	// unless the relevant Crossplane feature flag is enabled, and may be
	// changed or removed without notice.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	initProvider?: #TableInitParameters @go(InitProvider)
}

// TableStatus defines the observed state of Table.
#TableStatus: {
	atProvider?: #TableObservation @go(AtProvider)
}

// Table is the Schema for the Tables API. Creates a table resource in a dataset for Google BigQuery.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:subresource:status
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,gcp}
#Table: {
	spec:    #TableSpec   @go(Spec)
	status?: #TableStatus @go(Status)
}

// TableList contains a list of Tables
#TableList: {
	items: [...#Table] @go(Items,[]Table)
}
