// Code generated by cue get go. DO NOT EDIT.

//cue:generate cue get go github.com/upbound/provider-azure/apis/datafactory/v1beta1

package v1beta1

#IntegrationRuntimeAzureInitParameters: {
	// Cluster will not be recycled and it will be used in next data flow activity run until TTL (time to live) is reached if this is set as false. Default is true.
	cleanupEnabled?: null | bool @go(CleanupEnabled,*bool)

	// Compute type of the cluster which will execute data flow job. Valid values are General, ComputeOptimized and MemoryOptimized. Defaults to General.
	computeType?: null | string @go(ComputeType,*string)

	// Core count of the cluster which will execute data flow job. Valid values are 8, 16, 32, 48, 80, 144 and 272. Defaults to 8.
	coreCount?: null | float64 @go(CoreCount,*float64)

	// Integration runtime description.
	description?: null | string @go(Description,*string)

	// Specifies the supported Azure location where the resource exists. Use AutoResolve to create an auto-resolve integration runtime. Changing this forces a new resource to be created.
	location?: null | string @go(Location,*string)

	// Time to live (in minutes) setting of the cluster which will execute data flow job. Defaults to 0.
	timeToLiveMin?: null | float64 @go(TimeToLiveMin,*float64)

	// Is Integration Runtime compute provisioned within Managed Virtual Network? Changing this forces a new resource to be created.
	virtualNetworkEnabled?: null | bool @go(VirtualNetworkEnabled,*bool)
}

#IntegrationRuntimeAzureObservation: {
	// Cluster will not be recycled and it will be used in next data flow activity run until TTL (time to live) is reached if this is set as false. Default is true.
	cleanupEnabled?: null | bool @go(CleanupEnabled,*bool)

	// Compute type of the cluster which will execute data flow job. Valid values are General, ComputeOptimized and MemoryOptimized. Defaults to General.
	computeType?: null | string @go(ComputeType,*string)

	// Core count of the cluster which will execute data flow job. Valid values are 8, 16, 32, 48, 80, 144 and 272. Defaults to 8.
	coreCount?: null | float64 @go(CoreCount,*float64)

	// The Data Factory ID in which to associate the Linked Service with. Changing this forces a new resource.
	dataFactoryId?: null | string @go(DataFactoryID,*string)

	// Integration runtime description.
	description?: null | string @go(Description,*string)
	id?:          null | string @go(ID,*string)

	// Specifies the supported Azure location where the resource exists. Use AutoResolve to create an auto-resolve integration runtime. Changing this forces a new resource to be created.
	location?: null | string @go(Location,*string)

	// Time to live (in minutes) setting of the cluster which will execute data flow job. Defaults to 0.
	timeToLiveMin?: null | float64 @go(TimeToLiveMin,*float64)

	// Is Integration Runtime compute provisioned within Managed Virtual Network? Changing this forces a new resource to be created.
	virtualNetworkEnabled?: null | bool @go(VirtualNetworkEnabled,*bool)
}

#IntegrationRuntimeAzureParameters: {
	// Cluster will not be recycled and it will be used in next data flow activity run until TTL (time to live) is reached if this is set as false. Default is true.
	// +kubebuilder:validation:Optional
	cleanupEnabled?: null | bool @go(CleanupEnabled,*bool)

	// Compute type of the cluster which will execute data flow job. Valid values are General, ComputeOptimized and MemoryOptimized. Defaults to General.
	// +kubebuilder:validation:Optional
	computeType?: null | string @go(ComputeType,*string)

	// Core count of the cluster which will execute data flow job. Valid values are 8, 16, 32, 48, 80, 144 and 272. Defaults to 8.
	// +kubebuilder:validation:Optional
	coreCount?: null | float64 @go(CoreCount,*float64)

	// The Data Factory ID in which to associate the Linked Service with. Changing this forces a new resource.
	// +crossplane:generate:reference:type=github.com/upbound/provider-azure/apis/datafactory/v1beta1.Factory
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractResourceID()
	// +kubebuilder:validation:Optional
	dataFactoryId?: null | string @go(DataFactoryID,*string)

	// Integration runtime description.
	// +kubebuilder:validation:Optional
	description?: null | string @go(Description,*string)

	// Specifies the supported Azure location where the resource exists. Use AutoResolve to create an auto-resolve integration runtime. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	location?: null | string @go(Location,*string)

	// Time to live (in minutes) setting of the cluster which will execute data flow job. Defaults to 0.
	// +kubebuilder:validation:Optional
	timeToLiveMin?: null | float64 @go(TimeToLiveMin,*float64)

	// Is Integration Runtime compute provisioned within Managed Virtual Network? Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	virtualNetworkEnabled?: null | bool @go(VirtualNetworkEnabled,*bool)
}

// IntegrationRuntimeAzureSpec defines the desired state of IntegrationRuntimeAzure
#IntegrationRuntimeAzureSpec: {
	forProvider: #IntegrationRuntimeAzureParameters @go(ForProvider)

	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	initProvider?: #IntegrationRuntimeAzureInitParameters @go(InitProvider)
}

// IntegrationRuntimeAzureStatus defines the observed state of IntegrationRuntimeAzure.
#IntegrationRuntimeAzureStatus: {
	atProvider?: #IntegrationRuntimeAzureObservation @go(AtProvider)
}

// IntegrationRuntimeAzure is the Schema for the IntegrationRuntimeAzures API. Manages a Data Factory Azure Integration Runtime.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:subresource:status
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,azure}
#IntegrationRuntimeAzure: {
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.location) || (has(self.initProvider) && has(self.initProvider.location))",message="spec.forProvider.location is a required parameter"
	spec:    #IntegrationRuntimeAzureSpec   @go(Spec)
	status?: #IntegrationRuntimeAzureStatus @go(Status)
}

// IntegrationRuntimeAzureList contains a list of IntegrationRuntimeAzures
#IntegrationRuntimeAzureList: {
	items: [...#IntegrationRuntimeAzure] @go(Items,[]IntegrationRuntimeAzure)
}
