// Code generated by cue get go. DO NOT EDIT.

//cue:generate cue get go github.com/upbound/provider-azure/apis/hdinsight/v1beta1

package v1beta1

#RolesWorkerNodeAutoscaleRecurrenceInitParameters: {
	// A list of schedule blocks as defined below.
	schedule?: [...#WorkerNodeAutoscaleRecurrenceScheduleInitParameters] @go(Schedule,[]WorkerNodeAutoscaleRecurrenceScheduleInitParameters)

	// The time zone for the autoscale schedule times.
	timezone?: null | string @go(Timezone,*string)
}

#RolesWorkerNodeAutoscaleRecurrenceObservation: {
	// A list of schedule blocks as defined below.
	schedule?: [...#WorkerNodeAutoscaleRecurrenceScheduleObservation] @go(Schedule,[]WorkerNodeAutoscaleRecurrenceScheduleObservation)

	// The time zone for the autoscale schedule times.
	timezone?: null | string @go(Timezone,*string)
}

#RolesWorkerNodeAutoscaleRecurrenceParameters: {
	// A list of schedule blocks as defined below.
	// +kubebuilder:validation:Optional
	schedule: [...#WorkerNodeAutoscaleRecurrenceScheduleParameters] @go(Schedule,[]WorkerNodeAutoscaleRecurrenceScheduleParameters)

	// The time zone for the autoscale schedule times.
	// +kubebuilder:validation:Optional
	timezone?: null | string @go(Timezone,*string)
}

#SparkClusterComponentVersionInitParameters: {
	// The version of Spark which should be used for this HDInsight Spark Cluster. Changing this forces a new resource to be created.
	spark?: null | string @go(Spark,*string)
}

#SparkClusterComponentVersionObservation: {
	// The version of Spark which should be used for this HDInsight Spark Cluster. Changing this forces a new resource to be created.
	spark?: null | string @go(Spark,*string)
}

#SparkClusterComponentVersionParameters: {
	// The version of Spark which should be used for this HDInsight Spark Cluster. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	spark?: null | string @go(Spark,*string)
}

#SparkClusterComputeIsolationInitParameters: {
	// This field indicates whether enable compute isolation or not. Possible values are true or false.
	computeIsolationEnabled?: null | bool @go(ComputeIsolationEnabled,*bool)

	// The name of the host SKU.
	hostSku?: null | string @go(HostSku,*string)
}

#SparkClusterComputeIsolationObservation: {
	// This field indicates whether enable compute isolation or not. Possible values are true or false.
	computeIsolationEnabled?: null | bool @go(ComputeIsolationEnabled,*bool)

	// The name of the host SKU.
	hostSku?: null | string @go(HostSku,*string)
}

#SparkClusterComputeIsolationParameters: {
	// This field indicates whether enable compute isolation or not. Possible values are true or false.
	// +kubebuilder:validation:Optional
	computeIsolationEnabled?: null | bool @go(ComputeIsolationEnabled,*bool)

	// The name of the host SKU.
	// +kubebuilder:validation:Optional
	hostSku?: null | string @go(HostSku,*string)
}

#SparkClusterDiskEncryptionInitParameters: {
	// This is an algorithm identifier for encryption. Possible values are RSA1_5, RSA-OAEP, RSA-OAEP-256.
	encryptionAlgorithm?: null | string @go(EncryptionAlgorithm,*string)

	// This is indicator to show whether resource disk encryption is enabled.
	encryptionAtHostEnabled?: null | bool @go(EncryptionAtHostEnabled,*bool)

	// The ID of the key vault key.
	keyVaultKeyId?: null | string @go(KeyVaultKeyID,*string)

	// This is the resource ID of Managed Identity used to access the key vault.
	keyVaultManagedIdentityId?: null | string @go(KeyVaultManagedIdentityID,*string)
}

#SparkClusterDiskEncryptionObservation: {
	// This is an algorithm identifier for encryption. Possible values are RSA1_5, RSA-OAEP, RSA-OAEP-256.
	encryptionAlgorithm?: null | string @go(EncryptionAlgorithm,*string)

	// This is indicator to show whether resource disk encryption is enabled.
	encryptionAtHostEnabled?: null | bool @go(EncryptionAtHostEnabled,*bool)

	// The ID of the key vault key.
	keyVaultKeyId?: null | string @go(KeyVaultKeyID,*string)

	// This is the resource ID of Managed Identity used to access the key vault.
	keyVaultManagedIdentityId?: null | string @go(KeyVaultManagedIdentityID,*string)
}

#SparkClusterDiskEncryptionParameters: {
	// This is an algorithm identifier for encryption. Possible values are RSA1_5, RSA-OAEP, RSA-OAEP-256.
	// +kubebuilder:validation:Optional
	encryptionAlgorithm?: null | string @go(EncryptionAlgorithm,*string)

	// This is indicator to show whether resource disk encryption is enabled.
	// +kubebuilder:validation:Optional
	encryptionAtHostEnabled?: null | bool @go(EncryptionAtHostEnabled,*bool)

	// The ID of the key vault key.
	// +kubebuilder:validation:Optional
	keyVaultKeyId?: null | string @go(KeyVaultKeyID,*string)

	// This is the resource ID of Managed Identity used to access the key vault.
	// +kubebuilder:validation:Optional
	keyVaultManagedIdentityId?: null | string @go(KeyVaultManagedIdentityID,*string)
}

#SparkClusterExtensionInitParameters: {
	// The workspace ID of the log analytics extension.
	logAnalyticsWorkspaceId?: null | string @go(LogAnalyticsWorkspaceID,*string)
}

#SparkClusterExtensionObservation: {
	// The workspace ID of the log analytics extension.
	logAnalyticsWorkspaceId?: null | string @go(LogAnalyticsWorkspaceID,*string)
}

#SparkClusterExtensionParameters: {
	// The workspace ID of the log analytics extension.
	// +kubebuilder:validation:Optional
	logAnalyticsWorkspaceId?: null | string @go(LogAnalyticsWorkspaceID,*string)
}

#SparkClusterGatewayInitParameters: {
	// The username used for the Ambari Portal. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)
}

#SparkClusterGatewayObservation: {
	// The username used for the Ambari Portal. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)
}

#SparkClusterGatewayParameters: {
	// The username used for the Ambari Portal. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	username?: null | string @go(Username,*string)
}

#SparkClusterInitParameters: {
	// Specifies the Version of HDInsights which should be used for this Cluster. Changing this forces a new resource to be created.
	clusterVersion?: null | string @go(ClusterVersion,*string)

	// A component_version block as defined below.
	componentVersion?: [...#SparkClusterComponentVersionInitParameters] @go(ComponentVersion,[]SparkClusterComponentVersionInitParameters)

	// A compute_isolation block as defined below.
	computeIsolation?: [...#SparkClusterComputeIsolationInitParameters] @go(ComputeIsolation,[]SparkClusterComputeIsolationInitParameters)

	// One or more disk_encryption block as defined below.
	diskEncryption?: [...#SparkClusterDiskEncryptionInitParameters] @go(DiskEncryption,[]SparkClusterDiskEncryptionInitParameters)

	// Whether encryption in transit is enabled for this Cluster. Changing this forces a new resource to be created.
	encryptionInTransitEnabled?: null | bool @go(EncryptionInTransitEnabled,*bool)

	// An extension block as defined below.
	extension?: [...#SparkClusterExtensionInitParameters] @go(Extension,[]SparkClusterExtensionInitParameters)

	// A gateway block as defined below.
	gateway?: [...#SparkClusterGatewayInitParameters] @go(Gateway,[]SparkClusterGatewayInitParameters)

	// Specifies the Azure Region which this HDInsight Spark Cluster should exist. Changing this forces a new resource to be created.
	location?: null | string @go(Location,*string)

	// A metastores block as defined below.
	metastores?: [...#SparkClusterMetastoresInitParameters] @go(Metastores,[]SparkClusterMetastoresInitParameters)

	// A monitor block as defined below.
	monitor?: [...#SparkClusterMonitorInitParameters] @go(Monitor,[]SparkClusterMonitorInitParameters)

	// A network block as defined below.
	network?: [...#SparkClusterNetworkInitParameters] @go(Network,[]SparkClusterNetworkInitParameters)

	// A roles block as defined below.
	roles?: [...#SparkClusterRolesInitParameters] @go(Roles,[]SparkClusterRolesInitParameters)

	// A security_profile block as defined below. Changing this forces a new resource to be created.
	securityProfile?: [...#SparkClusterSecurityProfileInitParameters] @go(SecurityProfile,[]SparkClusterSecurityProfileInitParameters)

	// One or more storage_account block as defined below.
	storageAccount?: [...#SparkClusterStorageAccountInitParameters] @go(StorageAccount,[]SparkClusterStorageAccountInitParameters)

	// A storage_account_gen2 block as defined below.
	storageAccountGen2?: [...#SparkClusterStorageAccountGen2InitParameters] @go(StorageAccountGen2,[]SparkClusterStorageAccountGen2InitParameters)

	// The minimal supported TLS version. Possible values are 1.0, 1.1 or 1.2. Changing this forces a new resource to be created.
	tlsMinVersion?: null | string @go(TLSMinVersion,*string)

	// A map of Tags which should be assigned to this HDInsight Spark Cluster.
	tags?: {[string]: null | string} @go(Tags,map[string]*string)

	// Specifies the Tier which should be used for this HDInsight Spark Cluster. Possible values are Standard or Premium. Changing this forces a new resource to be created.
	tier?: null | string @go(Tier,*string)
}

#SparkClusterMetastoresAmbariInitParameters: {
	// The external Oozie metastore's existing SQL database. Changing this forces a new resource to be created.
	databaseName?: null | string @go(DatabaseName,*string)

	// The fully-qualified domain name (FQDN) of the SQL server to use for the external Oozie metastore. Changing this forces a new resource to be created.
	server?: null | string @go(Server,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)
}

#SparkClusterMetastoresAmbariObservation: {
	// The external Oozie metastore's existing SQL database. Changing this forces a new resource to be created.
	databaseName?: null | string @go(DatabaseName,*string)

	// The fully-qualified domain name (FQDN) of the SQL server to use for the external Oozie metastore. Changing this forces a new resource to be created.
	server?: null | string @go(Server,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)
}

#SparkClusterMetastoresAmbariParameters: {
	// The external Oozie metastore's existing SQL database. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	databaseName?: null | string @go(DatabaseName,*string)

	// The fully-qualified domain name (FQDN) of the SQL server to use for the external Oozie metastore. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	server?: null | string @go(Server,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	username?: null | string @go(Username,*string)
}

#SparkClusterMetastoresHiveInitParameters: {
	// The external Oozie metastore's existing SQL database. Changing this forces a new resource to be created.
	databaseName?: null | string @go(DatabaseName,*string)

	// The fully-qualified domain name (FQDN) of the SQL server to use for the external Oozie metastore. Changing this forces a new resource to be created.
	server?: null | string @go(Server,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)
}

#SparkClusterMetastoresHiveObservation: {
	// The external Oozie metastore's existing SQL database. Changing this forces a new resource to be created.
	databaseName?: null | string @go(DatabaseName,*string)

	// The fully-qualified domain name (FQDN) of the SQL server to use for the external Oozie metastore. Changing this forces a new resource to be created.
	server?: null | string @go(Server,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)
}

#SparkClusterMetastoresHiveParameters: {
	// The external Oozie metastore's existing SQL database. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	databaseName?: null | string @go(DatabaseName,*string)

	// The fully-qualified domain name (FQDN) of the SQL server to use for the external Oozie metastore. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	server?: null | string @go(Server,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	username?: null | string @go(Username,*string)
}

#SparkClusterMetastoresInitParameters: {
	// An ambari block as defined below.
	ambari?: [...#SparkClusterMetastoresAmbariInitParameters] @go(Ambari,[]SparkClusterMetastoresAmbariInitParameters)

	// A hive block as defined below.
	hive?: [...#SparkClusterMetastoresHiveInitParameters] @go(Hive,[]SparkClusterMetastoresHiveInitParameters)

	// An oozie block as defined below.
	oozie?: [...#SparkClusterMetastoresOozieInitParameters] @go(Oozie,[]SparkClusterMetastoresOozieInitParameters)
}

#SparkClusterMetastoresObservation: {
	// An ambari block as defined below.
	ambari?: [...#SparkClusterMetastoresAmbariObservation] @go(Ambari,[]SparkClusterMetastoresAmbariObservation)

	// A hive block as defined below.
	hive?: [...#SparkClusterMetastoresHiveObservation] @go(Hive,[]SparkClusterMetastoresHiveObservation)

	// An oozie block as defined below.
	oozie?: [...#SparkClusterMetastoresOozieObservation] @go(Oozie,[]SparkClusterMetastoresOozieObservation)
}

#SparkClusterMetastoresOozieInitParameters: {
	// The external Oozie metastore's existing SQL database. Changing this forces a new resource to be created.
	databaseName?: null | string @go(DatabaseName,*string)

	// The fully-qualified domain name (FQDN) of the SQL server to use for the external Oozie metastore. Changing this forces a new resource to be created.
	server?: null | string @go(Server,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)
}

#SparkClusterMetastoresOozieObservation: {
	// The external Oozie metastore's existing SQL database. Changing this forces a new resource to be created.
	databaseName?: null | string @go(DatabaseName,*string)

	// The fully-qualified domain name (FQDN) of the SQL server to use for the external Oozie metastore. Changing this forces a new resource to be created.
	server?: null | string @go(Server,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)
}

#SparkClusterMetastoresOozieParameters: {
	// The external Oozie metastore's existing SQL database. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	databaseName?: null | string @go(DatabaseName,*string)

	// The fully-qualified domain name (FQDN) of the SQL server to use for the external Oozie metastore. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	server?: null | string @go(Server,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	username?: null | string @go(Username,*string)
}

#SparkClusterMetastoresParameters: {
	// An ambari block as defined below.
	// +kubebuilder:validation:Optional
	ambari?: [...#SparkClusterMetastoresAmbariParameters] @go(Ambari,[]SparkClusterMetastoresAmbariParameters)

	// A hive block as defined below.
	// +kubebuilder:validation:Optional
	hive?: [...#SparkClusterMetastoresHiveParameters] @go(Hive,[]SparkClusterMetastoresHiveParameters)

	// An oozie block as defined below.
	// +kubebuilder:validation:Optional
	oozie?: [...#SparkClusterMetastoresOozieParameters] @go(Oozie,[]SparkClusterMetastoresOozieParameters)
}

#SparkClusterMonitorInitParameters: {
	// The Operations Management Suite (OMS) workspace ID.
	logAnalyticsWorkspaceId?: null | string @go(LogAnalyticsWorkspaceID,*string)
}

#SparkClusterMonitorObservation: {
	// The Operations Management Suite (OMS) workspace ID.
	logAnalyticsWorkspaceId?: null | string @go(LogAnalyticsWorkspaceID,*string)
}

#SparkClusterMonitorParameters: {
	// The Operations Management Suite (OMS) workspace ID.
	// +kubebuilder:validation:Optional
	logAnalyticsWorkspaceId?: null | string @go(LogAnalyticsWorkspaceID,*string)
}

#SparkClusterNetworkInitParameters: {
	// The direction of the resource provider connection. Possible values include Inbound or Outbound. Defaults to Inbound. Changing this forces a new resource to be created.
	connectionDirection?: null | string @go(ConnectionDirection,*string)

	// Is the private link enabled? Possible values include True or False. Defaults to False. Changing this forces a new resource to be created.
	privateLinkEnabled?: null | bool @go(PrivateLinkEnabled,*bool)
}

#SparkClusterNetworkObservation: {
	// The direction of the resource provider connection. Possible values include Inbound or Outbound. Defaults to Inbound. Changing this forces a new resource to be created.
	connectionDirection?: null | string @go(ConnectionDirection,*string)

	// Is the private link enabled? Possible values include True or False. Defaults to False. Changing this forces a new resource to be created.
	privateLinkEnabled?: null | bool @go(PrivateLinkEnabled,*bool)
}

#SparkClusterNetworkParameters: {
	// The direction of the resource provider connection. Possible values include Inbound or Outbound. Defaults to Inbound. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	connectionDirection?: null | string @go(ConnectionDirection,*string)

	// Is the private link enabled? Possible values include True or False. Defaults to False. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	privateLinkEnabled?: null | bool @go(PrivateLinkEnabled,*bool)
}

#SparkClusterObservation: {
	// Specifies the Version of HDInsights which should be used for this Cluster. Changing this forces a new resource to be created.
	clusterVersion?: null | string @go(ClusterVersion,*string)

	// A component_version block as defined below.
	componentVersion?: [...#SparkClusterComponentVersionObservation] @go(ComponentVersion,[]SparkClusterComponentVersionObservation)

	// A compute_isolation block as defined below.
	computeIsolation?: [...#SparkClusterComputeIsolationObservation] @go(ComputeIsolation,[]SparkClusterComputeIsolationObservation)

	// One or more disk_encryption block as defined below.
	diskEncryption?: [...#SparkClusterDiskEncryptionObservation] @go(DiskEncryption,[]SparkClusterDiskEncryptionObservation)

	// Whether encryption in transit is enabled for this Cluster. Changing this forces a new resource to be created.
	encryptionInTransitEnabled?: null | bool @go(EncryptionInTransitEnabled,*bool)

	// An extension block as defined below.
	extension?: [...#SparkClusterExtensionObservation] @go(Extension,[]SparkClusterExtensionObservation)

	// A gateway block as defined below.
	gateway?: [...#SparkClusterGatewayObservation] @go(Gateway,[]SparkClusterGatewayObservation)

	// The HTTPS Connectivity Endpoint for this HDInsight Spark Cluster.
	httpsEndpoint?: null | string @go(HTTPSEndpoint,*string)

	// The ID of the HDInsight Spark Cluster.
	id?: null | string @go(ID,*string)

	// Specifies the Azure Region which this HDInsight Spark Cluster should exist. Changing this forces a new resource to be created.
	location?: null | string @go(Location,*string)

	// A metastores block as defined below.
	metastores?: [...#SparkClusterMetastoresObservation] @go(Metastores,[]SparkClusterMetastoresObservation)

	// A monitor block as defined below.
	monitor?: [...#SparkClusterMonitorObservation] @go(Monitor,[]SparkClusterMonitorObservation)

	// A network block as defined below.
	network?: [...#SparkClusterNetworkObservation] @go(Network,[]SparkClusterNetworkObservation)

	// Specifies the name of the Resource Group in which this HDInsight Spark Cluster should exist. Changing this forces a new resource to be created.
	resourceGroupName?: null | string @go(ResourceGroupName,*string)

	// A roles block as defined below.
	roles?: [...#SparkClusterRolesObservation] @go(Roles,[]SparkClusterRolesObservation)

	// The SSH Connectivity Endpoint for this HDInsight Spark Cluster.
	sshEndpoint?: null | string @go(SSHEndpoint,*string)

	// A security_profile block as defined below. Changing this forces a new resource to be created.
	securityProfile?: [...#SparkClusterSecurityProfileObservation] @go(SecurityProfile,[]SparkClusterSecurityProfileObservation)

	// One or more storage_account block as defined below.
	storageAccount?: [...#SparkClusterStorageAccountObservation] @go(StorageAccount,[]SparkClusterStorageAccountObservation)

	// A storage_account_gen2 block as defined below.
	storageAccountGen2?: [...#SparkClusterStorageAccountGen2Observation] @go(StorageAccountGen2,[]SparkClusterStorageAccountGen2Observation)

	// The minimal supported TLS version. Possible values are 1.0, 1.1 or 1.2. Changing this forces a new resource to be created.
	tlsMinVersion?: null | string @go(TLSMinVersion,*string)

	// A map of Tags which should be assigned to this HDInsight Spark Cluster.
	tags?: {[string]: null | string} @go(Tags,map[string]*string)

	// Specifies the Tier which should be used for this HDInsight Spark Cluster. Possible values are Standard or Premium. Changing this forces a new resource to be created.
	tier?: null | string @go(Tier,*string)
}

#SparkClusterParameters: {
	// Specifies the Version of HDInsights which should be used for this Cluster. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	clusterVersion?: null | string @go(ClusterVersion,*string)

	// A component_version block as defined below.
	// +kubebuilder:validation:Optional
	componentVersion?: [...#SparkClusterComponentVersionParameters] @go(ComponentVersion,[]SparkClusterComponentVersionParameters)

	// A compute_isolation block as defined below.
	// +kubebuilder:validation:Optional
	computeIsolation?: [...#SparkClusterComputeIsolationParameters] @go(ComputeIsolation,[]SparkClusterComputeIsolationParameters)

	// One or more disk_encryption block as defined below.
	// +kubebuilder:validation:Optional
	diskEncryption?: [...#SparkClusterDiskEncryptionParameters] @go(DiskEncryption,[]SparkClusterDiskEncryptionParameters)

	// Whether encryption in transit is enabled for this Cluster. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	encryptionInTransitEnabled?: null | bool @go(EncryptionInTransitEnabled,*bool)

	// An extension block as defined below.
	// +kubebuilder:validation:Optional
	extension?: [...#SparkClusterExtensionParameters] @go(Extension,[]SparkClusterExtensionParameters)

	// A gateway block as defined below.
	// +kubebuilder:validation:Optional
	gateway?: [...#SparkClusterGatewayParameters] @go(Gateway,[]SparkClusterGatewayParameters)

	// Specifies the Azure Region which this HDInsight Spark Cluster should exist. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	location?: null | string @go(Location,*string)

	// A metastores block as defined below.
	// +kubebuilder:validation:Optional
	metastores?: [...#SparkClusterMetastoresParameters] @go(Metastores,[]SparkClusterMetastoresParameters)

	// A monitor block as defined below.
	// +kubebuilder:validation:Optional
	monitor?: [...#SparkClusterMonitorParameters] @go(Monitor,[]SparkClusterMonitorParameters)

	// A network block as defined below.
	// +kubebuilder:validation:Optional
	network?: [...#SparkClusterNetworkParameters] @go(Network,[]SparkClusterNetworkParameters)

	// Specifies the name of the Resource Group in which this HDInsight Spark Cluster should exist. Changing this forces a new resource to be created.
	// +crossplane:generate:reference:type=github.com/upbound/provider-azure/apis/azure/v1beta1.ResourceGroup
	// +kubebuilder:validation:Optional
	resourceGroupName?: null | string @go(ResourceGroupName,*string)

	// A roles block as defined below.
	// +kubebuilder:validation:Optional
	roles?: [...#SparkClusterRolesParameters] @go(Roles,[]SparkClusterRolesParameters)

	// A security_profile block as defined below. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	securityProfile?: [...#SparkClusterSecurityProfileParameters] @go(SecurityProfile,[]SparkClusterSecurityProfileParameters)

	// One or more storage_account block as defined below.
	// +kubebuilder:validation:Optional
	storageAccount?: [...#SparkClusterStorageAccountParameters] @go(StorageAccount,[]SparkClusterStorageAccountParameters)

	// A storage_account_gen2 block as defined below.
	// +kubebuilder:validation:Optional
	storageAccountGen2?: [...#SparkClusterStorageAccountGen2Parameters] @go(StorageAccountGen2,[]SparkClusterStorageAccountGen2Parameters)

	// The minimal supported TLS version. Possible values are 1.0, 1.1 or 1.2. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	tlsMinVersion?: null | string @go(TLSMinVersion,*string)

	// A map of Tags which should be assigned to this HDInsight Spark Cluster.
	// +kubebuilder:validation:Optional
	tags?: {[string]: null | string} @go(Tags,map[string]*string)

	// Specifies the Tier which should be used for this HDInsight Spark Cluster. Possible values are Standard or Premium. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	tier?: null | string @go(Tier,*string)
}

#SparkClusterRolesHeadNodeInitParameters: {
	// A list of SSH Keys which should be used for the local administrator on the Zookeeper Nodes. Changing this forces a new resource to be created.
	sshKeys?: [...null | string] @go(SSHKeys,[]*string)

	// The script action which will run on the cluster. Changing this forces a new resource to be created.
	scriptActions?: [...#SparkClusterRolesHeadNodeScriptActionsInitParameters] @go(ScriptActions,[]SparkClusterRolesHeadNodeScriptActionsInitParameters)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)

	// The Size of the Virtual Machine which should be used as the Zookeeper Nodes. Possible values are ExtraSmall, Small, Medium, Large, ExtraLarge, A5, A6, A7, A8, A9, A10, A11, Standard_A1_V2, Standard_A2_V2, Standard_A2m_V2, Standard_A3, Standard_A4_V2, Standard_A4m_V2, Standard_A8_V2, Standard_A8m_V2, Standard_D1, Standard_D2, Standard_D3, Standard_D4, Standard_D11, Standard_D12, Standard_D13, Standard_D14, Standard_D1_V2, Standard_D2_V2, Standard_D3_V2, Standard_D4_V2, Standard_D5_V2, Standard_D11_V2, Standard_D12_V2, Standard_D13_V2, Standard_D14_V2, Standard_DS1_V2, Standard_DS2_V2, Standard_DS3_V2, Standard_DS4_V2, Standard_DS5_V2, Standard_DS11_V2, Standard_DS12_V2, Standard_DS13_V2, Standard_DS14_V2, Standard_E2_V3, Standard_E4_V3, Standard_E8_V3, Standard_E16_V3, Standard_E20_V3, Standard_E32_V3, Standard_E64_V3, Standard_E64i_V3, Standard_E2s_V3, Standard_E4s_V3, Standard_E8s_V3, Standard_E16s_V3, Standard_E20s_V3, Standard_E32s_V3, Standard_E64s_V3, Standard_E64is_V3, Standard_D2a_V4, Standard_D4a_V4, Standard_D8a_V4, Standard_D16a_V4, Standard_D32a_V4, Standard_D48a_V4, Standard_D64a_V4, Standard_D96a_V4, Standard_E2a_V4, Standard_E4a_V4, Standard_E8a_V4, Standard_E16a_V4, Standard_E20a_V4, Standard_E32a_V4, Standard_E48a_V4, Standard_E64a_V4, Standard_E96a_V4, Standard_G1, Standard_G2, Standard_G3, Standard_G4, Standard_G5, Standard_F2s_V2, Standard_F4s_V2, Standard_F8s_V2, Standard_F16s_V2, Standard_F32s_V2, Standard_F64s_V2, Standard_F72s_V2, Standard_GS1, Standard_GS2, Standard_GS3, Standard_GS4, Standard_GS5 and Standard_NC24. Changing this forces a new resource to be created.
	vmSize?: null | string @go(VMSize,*string)

	// The ID of the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	virtualNetworkId?: null | string @go(VirtualNetworkID,*string)
}

#SparkClusterRolesHeadNodeObservation: {
	// A list of SSH Keys which should be used for the local administrator on the Zookeeper Nodes. Changing this forces a new resource to be created.
	sshKeys?: [...null | string] @go(SSHKeys,[]*string)

	// The script action which will run on the cluster. Changing this forces a new resource to be created.
	scriptActions?: [...#SparkClusterRolesHeadNodeScriptActionsObservation] @go(ScriptActions,[]SparkClusterRolesHeadNodeScriptActionsObservation)

	// The ID of the Subnet within the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	subnetId?: null | string @go(SubnetID,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)

	// The Size of the Virtual Machine which should be used as the Zookeeper Nodes. Possible values are ExtraSmall, Small, Medium, Large, ExtraLarge, A5, A6, A7, A8, A9, A10, A11, Standard_A1_V2, Standard_A2_V2, Standard_A2m_V2, Standard_A3, Standard_A4_V2, Standard_A4m_V2, Standard_A8_V2, Standard_A8m_V2, Standard_D1, Standard_D2, Standard_D3, Standard_D4, Standard_D11, Standard_D12, Standard_D13, Standard_D14, Standard_D1_V2, Standard_D2_V2, Standard_D3_V2, Standard_D4_V2, Standard_D5_V2, Standard_D11_V2, Standard_D12_V2, Standard_D13_V2, Standard_D14_V2, Standard_DS1_V2, Standard_DS2_V2, Standard_DS3_V2, Standard_DS4_V2, Standard_DS5_V2, Standard_DS11_V2, Standard_DS12_V2, Standard_DS13_V2, Standard_DS14_V2, Standard_E2_V3, Standard_E4_V3, Standard_E8_V3, Standard_E16_V3, Standard_E20_V3, Standard_E32_V3, Standard_E64_V3, Standard_E64i_V3, Standard_E2s_V3, Standard_E4s_V3, Standard_E8s_V3, Standard_E16s_V3, Standard_E20s_V3, Standard_E32s_V3, Standard_E64s_V3, Standard_E64is_V3, Standard_D2a_V4, Standard_D4a_V4, Standard_D8a_V4, Standard_D16a_V4, Standard_D32a_V4, Standard_D48a_V4, Standard_D64a_V4, Standard_D96a_V4, Standard_E2a_V4, Standard_E4a_V4, Standard_E8a_V4, Standard_E16a_V4, Standard_E20a_V4, Standard_E32a_V4, Standard_E48a_V4, Standard_E64a_V4, Standard_E96a_V4, Standard_G1, Standard_G2, Standard_G3, Standard_G4, Standard_G5, Standard_F2s_V2, Standard_F4s_V2, Standard_F8s_V2, Standard_F16s_V2, Standard_F32s_V2, Standard_F64s_V2, Standard_F72s_V2, Standard_GS1, Standard_GS2, Standard_GS3, Standard_GS4, Standard_GS5 and Standard_NC24. Changing this forces a new resource to be created.
	vmSize?: null | string @go(VMSize,*string)

	// The ID of the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	virtualNetworkId?: null | string @go(VirtualNetworkID,*string)
}

#SparkClusterRolesHeadNodeParameters: {
	// A list of SSH Keys which should be used for the local administrator on the Zookeeper Nodes. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	sshKeys?: [...null | string] @go(SSHKeys,[]*string)

	// The script action which will run on the cluster. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	scriptActions?: [...#SparkClusterRolesHeadNodeScriptActionsParameters] @go(ScriptActions,[]SparkClusterRolesHeadNodeScriptActionsParameters)

	// The ID of the Subnet within the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	// +crossplane:generate:reference:type=github.com/upbound/provider-azure/apis/network/v1beta1.Subnet
	// +crossplane:generate:reference:extractor=github.com/upbound/provider-azure/apis/rconfig.ExtractResourceID()
	// +kubebuilder:validation:Optional
	subnetId?: null | string @go(SubnetID,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	username?: null | string @go(Username,*string)

	// The Size of the Virtual Machine which should be used as the Zookeeper Nodes. Possible values are ExtraSmall, Small, Medium, Large, ExtraLarge, A5, A6, A7, A8, A9, A10, A11, Standard_A1_V2, Standard_A2_V2, Standard_A2m_V2, Standard_A3, Standard_A4_V2, Standard_A4m_V2, Standard_A8_V2, Standard_A8m_V2, Standard_D1, Standard_D2, Standard_D3, Standard_D4, Standard_D11, Standard_D12, Standard_D13, Standard_D14, Standard_D1_V2, Standard_D2_V2, Standard_D3_V2, Standard_D4_V2, Standard_D5_V2, Standard_D11_V2, Standard_D12_V2, Standard_D13_V2, Standard_D14_V2, Standard_DS1_V2, Standard_DS2_V2, Standard_DS3_V2, Standard_DS4_V2, Standard_DS5_V2, Standard_DS11_V2, Standard_DS12_V2, Standard_DS13_V2, Standard_DS14_V2, Standard_E2_V3, Standard_E4_V3, Standard_E8_V3, Standard_E16_V3, Standard_E20_V3, Standard_E32_V3, Standard_E64_V3, Standard_E64i_V3, Standard_E2s_V3, Standard_E4s_V3, Standard_E8s_V3, Standard_E16s_V3, Standard_E20s_V3, Standard_E32s_V3, Standard_E64s_V3, Standard_E64is_V3, Standard_D2a_V4, Standard_D4a_V4, Standard_D8a_V4, Standard_D16a_V4, Standard_D32a_V4, Standard_D48a_V4, Standard_D64a_V4, Standard_D96a_V4, Standard_E2a_V4, Standard_E4a_V4, Standard_E8a_V4, Standard_E16a_V4, Standard_E20a_V4, Standard_E32a_V4, Standard_E48a_V4, Standard_E64a_V4, Standard_E96a_V4, Standard_G1, Standard_G2, Standard_G3, Standard_G4, Standard_G5, Standard_F2s_V2, Standard_F4s_V2, Standard_F8s_V2, Standard_F16s_V2, Standard_F32s_V2, Standard_F64s_V2, Standard_F72s_V2, Standard_GS1, Standard_GS2, Standard_GS3, Standard_GS4, Standard_GS5 and Standard_NC24. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	vmSize?: null | string @go(VMSize,*string)

	// The ID of the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	virtualNetworkId?: null | string @go(VirtualNetworkID,*string)
}

#SparkClusterRolesHeadNodeScriptActionsInitParameters: {
	// The name of the script action.
	name?: null | string @go(Name,*string)

	// The parameters for the script provided.
	parameters?: null | string @go(Parameters,*string)

	// The URI to the script.
	uri?: null | string @go(URI,*string)
}

#SparkClusterRolesHeadNodeScriptActionsObservation: {
	// The name of the script action.
	name?: null | string @go(Name,*string)

	// The parameters for the script provided.
	parameters?: null | string @go(Parameters,*string)

	// The URI to the script.
	uri?: null | string @go(URI,*string)
}

#SparkClusterRolesHeadNodeScriptActionsParameters: {
	// The name of the script action.
	// +kubebuilder:validation:Optional
	name?: null | string @go(Name,*string)

	// The parameters for the script provided.
	// +kubebuilder:validation:Optional
	parameters?: null | string @go(Parameters,*string)

	// The URI to the script.
	// +kubebuilder:validation:Optional
	uri?: null | string @go(URI,*string)
}

#SparkClusterRolesInitParameters: {
	// A head_node block as defined above.
	headNode?: [...#SparkClusterRolesHeadNodeInitParameters] @go(HeadNode,[]SparkClusterRolesHeadNodeInitParameters)

	// A worker_node block as defined below.
	workerNode?: [...#SparkClusterRolesWorkerNodeInitParameters] @go(WorkerNode,[]SparkClusterRolesWorkerNodeInitParameters)

	// A zookeeper_node block as defined below.
	zookeeperNode?: [...#SparkClusterRolesZookeeperNodeInitParameters] @go(ZookeeperNode,[]SparkClusterRolesZookeeperNodeInitParameters)
}

#SparkClusterRolesObservation: {
	// A head_node block as defined above.
	headNode?: [...#SparkClusterRolesHeadNodeObservation] @go(HeadNode,[]SparkClusterRolesHeadNodeObservation)

	// A worker_node block as defined below.
	workerNode?: [...#SparkClusterRolesWorkerNodeObservation] @go(WorkerNode,[]SparkClusterRolesWorkerNodeObservation)

	// A zookeeper_node block as defined below.
	zookeeperNode?: [...#SparkClusterRolesZookeeperNodeObservation] @go(ZookeeperNode,[]SparkClusterRolesZookeeperNodeObservation)
}

#SparkClusterRolesParameters: {
	// A head_node block as defined above.
	// +kubebuilder:validation:Optional
	headNode: [...#SparkClusterRolesHeadNodeParameters] @go(HeadNode,[]SparkClusterRolesHeadNodeParameters)

	// A worker_node block as defined below.
	// +kubebuilder:validation:Optional
	workerNode: [...#SparkClusterRolesWorkerNodeParameters] @go(WorkerNode,[]SparkClusterRolesWorkerNodeParameters)

	// A zookeeper_node block as defined below.
	// +kubebuilder:validation:Optional
	zookeeperNode: [...#SparkClusterRolesZookeeperNodeParameters] @go(ZookeeperNode,[]SparkClusterRolesZookeeperNodeParameters)
}

#SparkClusterRolesWorkerNodeAutoscaleInitParameters: {
	// A capacity block as defined below.
	capacity?: [...#WorkerNodeAutoscaleCapacityInitParameters] @go(Capacity,[]WorkerNodeAutoscaleCapacityInitParameters)

	// A recurrence block as defined below.
	recurrence?: [...#RolesWorkerNodeAutoscaleRecurrenceInitParameters] @go(Recurrence,[]RolesWorkerNodeAutoscaleRecurrenceInitParameters)
}

#SparkClusterRolesWorkerNodeAutoscaleObservation: {
	// A capacity block as defined below.
	capacity?: [...#WorkerNodeAutoscaleCapacityObservation] @go(Capacity,[]WorkerNodeAutoscaleCapacityObservation)

	// A recurrence block as defined below.
	recurrence?: [...#RolesWorkerNodeAutoscaleRecurrenceObservation] @go(Recurrence,[]RolesWorkerNodeAutoscaleRecurrenceObservation)
}

#SparkClusterRolesWorkerNodeAutoscaleParameters: {
	// A capacity block as defined below.
	// +kubebuilder:validation:Optional
	capacity?: [...#WorkerNodeAutoscaleCapacityParameters] @go(Capacity,[]WorkerNodeAutoscaleCapacityParameters)

	// A recurrence block as defined below.
	// +kubebuilder:validation:Optional
	recurrence?: [...#RolesWorkerNodeAutoscaleRecurrenceParameters] @go(Recurrence,[]RolesWorkerNodeAutoscaleRecurrenceParameters)
}

#SparkClusterRolesWorkerNodeInitParameters: {
	// A autoscale block as defined below.
	autoscale?: [...#SparkClusterRolesWorkerNodeAutoscaleInitParameters] @go(Autoscale,[]SparkClusterRolesWorkerNodeAutoscaleInitParameters)

	// A list of SSH Keys which should be used for the local administrator on the Zookeeper Nodes. Changing this forces a new resource to be created.
	sshKeys?: [...null | string] @go(SSHKeys,[]*string)

	// The script action which will run on the cluster. Changing this forces a new resource to be created.
	scriptActions?: [...#SparkClusterRolesWorkerNodeScriptActionsInitParameters] @go(ScriptActions,[]SparkClusterRolesWorkerNodeScriptActionsInitParameters)

	// The number of instances which should be run for the Worker Nodes.
	targetInstanceCount?: null | float64 @go(TargetInstanceCount,*float64)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)

	// The Size of the Virtual Machine which should be used as the Zookeeper Nodes. Possible values are ExtraSmall, Small, Medium, Large, ExtraLarge, A5, A6, A7, A8, A9, A10, A11, Standard_A1_V2, Standard_A2_V2, Standard_A2m_V2, Standard_A3, Standard_A4_V2, Standard_A4m_V2, Standard_A8_V2, Standard_A8m_V2, Standard_D1, Standard_D2, Standard_D3, Standard_D4, Standard_D11, Standard_D12, Standard_D13, Standard_D14, Standard_D1_V2, Standard_D2_V2, Standard_D3_V2, Standard_D4_V2, Standard_D5_V2, Standard_D11_V2, Standard_D12_V2, Standard_D13_V2, Standard_D14_V2, Standard_DS1_V2, Standard_DS2_V2, Standard_DS3_V2, Standard_DS4_V2, Standard_DS5_V2, Standard_DS11_V2, Standard_DS12_V2, Standard_DS13_V2, Standard_DS14_V2, Standard_E2_V3, Standard_E4_V3, Standard_E8_V3, Standard_E16_V3, Standard_E20_V3, Standard_E32_V3, Standard_E64_V3, Standard_E64i_V3, Standard_E2s_V3, Standard_E4s_V3, Standard_E8s_V3, Standard_E16s_V3, Standard_E20s_V3, Standard_E32s_V3, Standard_E64s_V3, Standard_E64is_V3, Standard_D2a_V4, Standard_D4a_V4, Standard_D8a_V4, Standard_D16a_V4, Standard_D32a_V4, Standard_D48a_V4, Standard_D64a_V4, Standard_D96a_V4, Standard_E2a_V4, Standard_E4a_V4, Standard_E8a_V4, Standard_E16a_V4, Standard_E20a_V4, Standard_E32a_V4, Standard_E48a_V4, Standard_E64a_V4, Standard_E96a_V4, Standard_G1, Standard_G2, Standard_G3, Standard_G4, Standard_G5, Standard_F2s_V2, Standard_F4s_V2, Standard_F8s_V2, Standard_F16s_V2, Standard_F32s_V2, Standard_F64s_V2, Standard_F72s_V2, Standard_GS1, Standard_GS2, Standard_GS3, Standard_GS4, Standard_GS5 and Standard_NC24. Changing this forces a new resource to be created.
	vmSize?: null | string @go(VMSize,*string)

	// The ID of the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	virtualNetworkId?: null | string @go(VirtualNetworkID,*string)
}

#SparkClusterRolesWorkerNodeObservation: {
	// A autoscale block as defined below.
	autoscale?: [...#SparkClusterRolesWorkerNodeAutoscaleObservation] @go(Autoscale,[]SparkClusterRolesWorkerNodeAutoscaleObservation)

	// A list of SSH Keys which should be used for the local administrator on the Zookeeper Nodes. Changing this forces a new resource to be created.
	sshKeys?: [...null | string] @go(SSHKeys,[]*string)

	// The script action which will run on the cluster. Changing this forces a new resource to be created.
	scriptActions?: [...#SparkClusterRolesWorkerNodeScriptActionsObservation] @go(ScriptActions,[]SparkClusterRolesWorkerNodeScriptActionsObservation)

	// The ID of the Subnet within the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	subnetId?: null | string @go(SubnetID,*string)

	// The number of instances which should be run for the Worker Nodes.
	targetInstanceCount?: null | float64 @go(TargetInstanceCount,*float64)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)

	// The Size of the Virtual Machine which should be used as the Zookeeper Nodes. Possible values are ExtraSmall, Small, Medium, Large, ExtraLarge, A5, A6, A7, A8, A9, A10, A11, Standard_A1_V2, Standard_A2_V2, Standard_A2m_V2, Standard_A3, Standard_A4_V2, Standard_A4m_V2, Standard_A8_V2, Standard_A8m_V2, Standard_D1, Standard_D2, Standard_D3, Standard_D4, Standard_D11, Standard_D12, Standard_D13, Standard_D14, Standard_D1_V2, Standard_D2_V2, Standard_D3_V2, Standard_D4_V2, Standard_D5_V2, Standard_D11_V2, Standard_D12_V2, Standard_D13_V2, Standard_D14_V2, Standard_DS1_V2, Standard_DS2_V2, Standard_DS3_V2, Standard_DS4_V2, Standard_DS5_V2, Standard_DS11_V2, Standard_DS12_V2, Standard_DS13_V2, Standard_DS14_V2, Standard_E2_V3, Standard_E4_V3, Standard_E8_V3, Standard_E16_V3, Standard_E20_V3, Standard_E32_V3, Standard_E64_V3, Standard_E64i_V3, Standard_E2s_V3, Standard_E4s_V3, Standard_E8s_V3, Standard_E16s_V3, Standard_E20s_V3, Standard_E32s_V3, Standard_E64s_V3, Standard_E64is_V3, Standard_D2a_V4, Standard_D4a_V4, Standard_D8a_V4, Standard_D16a_V4, Standard_D32a_V4, Standard_D48a_V4, Standard_D64a_V4, Standard_D96a_V4, Standard_E2a_V4, Standard_E4a_V4, Standard_E8a_V4, Standard_E16a_V4, Standard_E20a_V4, Standard_E32a_V4, Standard_E48a_V4, Standard_E64a_V4, Standard_E96a_V4, Standard_G1, Standard_G2, Standard_G3, Standard_G4, Standard_G5, Standard_F2s_V2, Standard_F4s_V2, Standard_F8s_V2, Standard_F16s_V2, Standard_F32s_V2, Standard_F64s_V2, Standard_F72s_V2, Standard_GS1, Standard_GS2, Standard_GS3, Standard_GS4, Standard_GS5 and Standard_NC24. Changing this forces a new resource to be created.
	vmSize?: null | string @go(VMSize,*string)

	// The ID of the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	virtualNetworkId?: null | string @go(VirtualNetworkID,*string)
}

#SparkClusterRolesWorkerNodeParameters: {
	// A autoscale block as defined below.
	// +kubebuilder:validation:Optional
	autoscale?: [...#SparkClusterRolesWorkerNodeAutoscaleParameters] @go(Autoscale,[]SparkClusterRolesWorkerNodeAutoscaleParameters)

	// A list of SSH Keys which should be used for the local administrator on the Zookeeper Nodes. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	sshKeys?: [...null | string] @go(SSHKeys,[]*string)

	// The script action which will run on the cluster. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	scriptActions?: [...#SparkClusterRolesWorkerNodeScriptActionsParameters] @go(ScriptActions,[]SparkClusterRolesWorkerNodeScriptActionsParameters)

	// The ID of the Subnet within the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	// +crossplane:generate:reference:type=github.com/upbound/provider-azure/apis/network/v1beta1.Subnet
	// +crossplane:generate:reference:extractor=github.com/upbound/provider-azure/apis/rconfig.ExtractResourceID()
	// +kubebuilder:validation:Optional
	subnetId?: null | string @go(SubnetID,*string)

	// The number of instances which should be run for the Worker Nodes.
	// +kubebuilder:validation:Optional
	targetInstanceCount?: null | float64 @go(TargetInstanceCount,*float64)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	username?: null | string @go(Username,*string)

	// The Size of the Virtual Machine which should be used as the Zookeeper Nodes. Possible values are ExtraSmall, Small, Medium, Large, ExtraLarge, A5, A6, A7, A8, A9, A10, A11, Standard_A1_V2, Standard_A2_V2, Standard_A2m_V2, Standard_A3, Standard_A4_V2, Standard_A4m_V2, Standard_A8_V2, Standard_A8m_V2, Standard_D1, Standard_D2, Standard_D3, Standard_D4, Standard_D11, Standard_D12, Standard_D13, Standard_D14, Standard_D1_V2, Standard_D2_V2, Standard_D3_V2, Standard_D4_V2, Standard_D5_V2, Standard_D11_V2, Standard_D12_V2, Standard_D13_V2, Standard_D14_V2, Standard_DS1_V2, Standard_DS2_V2, Standard_DS3_V2, Standard_DS4_V2, Standard_DS5_V2, Standard_DS11_V2, Standard_DS12_V2, Standard_DS13_V2, Standard_DS14_V2, Standard_E2_V3, Standard_E4_V3, Standard_E8_V3, Standard_E16_V3, Standard_E20_V3, Standard_E32_V3, Standard_E64_V3, Standard_E64i_V3, Standard_E2s_V3, Standard_E4s_V3, Standard_E8s_V3, Standard_E16s_V3, Standard_E20s_V3, Standard_E32s_V3, Standard_E64s_V3, Standard_E64is_V3, Standard_D2a_V4, Standard_D4a_V4, Standard_D8a_V4, Standard_D16a_V4, Standard_D32a_V4, Standard_D48a_V4, Standard_D64a_V4, Standard_D96a_V4, Standard_E2a_V4, Standard_E4a_V4, Standard_E8a_V4, Standard_E16a_V4, Standard_E20a_V4, Standard_E32a_V4, Standard_E48a_V4, Standard_E64a_V4, Standard_E96a_V4, Standard_G1, Standard_G2, Standard_G3, Standard_G4, Standard_G5, Standard_F2s_V2, Standard_F4s_V2, Standard_F8s_V2, Standard_F16s_V2, Standard_F32s_V2, Standard_F64s_V2, Standard_F72s_V2, Standard_GS1, Standard_GS2, Standard_GS3, Standard_GS4, Standard_GS5 and Standard_NC24. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	vmSize?: null | string @go(VMSize,*string)

	// The ID of the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	virtualNetworkId?: null | string @go(VirtualNetworkID,*string)
}

#SparkClusterRolesWorkerNodeScriptActionsInitParameters: {
	// The name of the script action.
	name?: null | string @go(Name,*string)

	// The parameters for the script provided.
	parameters?: null | string @go(Parameters,*string)

	// The URI to the script.
	uri?: null | string @go(URI,*string)
}

#SparkClusterRolesWorkerNodeScriptActionsObservation: {
	// The name of the script action.
	name?: null | string @go(Name,*string)

	// The parameters for the script provided.
	parameters?: null | string @go(Parameters,*string)

	// The URI to the script.
	uri?: null | string @go(URI,*string)
}

#SparkClusterRolesWorkerNodeScriptActionsParameters: {
	// The name of the script action.
	// +kubebuilder:validation:Optional
	name?: null | string @go(Name,*string)

	// The parameters for the script provided.
	// +kubebuilder:validation:Optional
	parameters?: null | string @go(Parameters,*string)

	// The URI to the script.
	// +kubebuilder:validation:Optional
	uri?: null | string @go(URI,*string)
}

#SparkClusterRolesZookeeperNodeInitParameters: {
	// A list of SSH Keys which should be used for the local administrator on the Zookeeper Nodes. Changing this forces a new resource to be created.
	sshKeys?: [...null | string] @go(SSHKeys,[]*string)

	// The script action which will run on the cluster. Changing this forces a new resource to be created.
	scriptActions?: [...#SparkClusterRolesZookeeperNodeScriptActionsInitParameters] @go(ScriptActions,[]SparkClusterRolesZookeeperNodeScriptActionsInitParameters)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)

	// The Size of the Virtual Machine which should be used as the Zookeeper Nodes. Possible values are ExtraSmall, Small, Medium, Large, ExtraLarge, A5, A6, A7, A8, A9, A10, A11, Standard_A1_V2, Standard_A2_V2, Standard_A2m_V2, Standard_A3, Standard_A4_V2, Standard_A4m_V2, Standard_A8_V2, Standard_A8m_V2, Standard_D1, Standard_D2, Standard_D3, Standard_D4, Standard_D11, Standard_D12, Standard_D13, Standard_D14, Standard_D1_V2, Standard_D2_V2, Standard_D3_V2, Standard_D4_V2, Standard_D5_V2, Standard_D11_V2, Standard_D12_V2, Standard_D13_V2, Standard_D14_V2, Standard_DS1_V2, Standard_DS2_V2, Standard_DS3_V2, Standard_DS4_V2, Standard_DS5_V2, Standard_DS11_V2, Standard_DS12_V2, Standard_DS13_V2, Standard_DS14_V2, Standard_E2_V3, Standard_E4_V3, Standard_E8_V3, Standard_E16_V3, Standard_E20_V3, Standard_E32_V3, Standard_E64_V3, Standard_E64i_V3, Standard_E2s_V3, Standard_E4s_V3, Standard_E8s_V3, Standard_E16s_V3, Standard_E20s_V3, Standard_E32s_V3, Standard_E64s_V3, Standard_E64is_V3, Standard_D2a_V4, Standard_D4a_V4, Standard_D8a_V4, Standard_D16a_V4, Standard_D32a_V4, Standard_D48a_V4, Standard_D64a_V4, Standard_D96a_V4, Standard_E2a_V4, Standard_E4a_V4, Standard_E8a_V4, Standard_E16a_V4, Standard_E20a_V4, Standard_E32a_V4, Standard_E48a_V4, Standard_E64a_V4, Standard_E96a_V4, Standard_G1, Standard_G2, Standard_G3, Standard_G4, Standard_G5, Standard_F2s_V2, Standard_F4s_V2, Standard_F8s_V2, Standard_F16s_V2, Standard_F32s_V2, Standard_F64s_V2, Standard_F72s_V2, Standard_GS1, Standard_GS2, Standard_GS3, Standard_GS4, Standard_GS5 and Standard_NC24. Changing this forces a new resource to be created.
	vmSize?: null | string @go(VMSize,*string)

	// The ID of the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	virtualNetworkId?: null | string @go(VirtualNetworkID,*string)
}

#SparkClusterRolesZookeeperNodeObservation: {
	// A list of SSH Keys which should be used for the local administrator on the Zookeeper Nodes. Changing this forces a new resource to be created.
	sshKeys?: [...null | string] @go(SSHKeys,[]*string)

	// The script action which will run on the cluster. Changing this forces a new resource to be created.
	scriptActions?: [...#SparkClusterRolesZookeeperNodeScriptActionsObservation] @go(ScriptActions,[]SparkClusterRolesZookeeperNodeScriptActionsObservation)

	// The ID of the Subnet within the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	subnetId?: null | string @go(SubnetID,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	username?: null | string @go(Username,*string)

	// The Size of the Virtual Machine which should be used as the Zookeeper Nodes. Possible values are ExtraSmall, Small, Medium, Large, ExtraLarge, A5, A6, A7, A8, A9, A10, A11, Standard_A1_V2, Standard_A2_V2, Standard_A2m_V2, Standard_A3, Standard_A4_V2, Standard_A4m_V2, Standard_A8_V2, Standard_A8m_V2, Standard_D1, Standard_D2, Standard_D3, Standard_D4, Standard_D11, Standard_D12, Standard_D13, Standard_D14, Standard_D1_V2, Standard_D2_V2, Standard_D3_V2, Standard_D4_V2, Standard_D5_V2, Standard_D11_V2, Standard_D12_V2, Standard_D13_V2, Standard_D14_V2, Standard_DS1_V2, Standard_DS2_V2, Standard_DS3_V2, Standard_DS4_V2, Standard_DS5_V2, Standard_DS11_V2, Standard_DS12_V2, Standard_DS13_V2, Standard_DS14_V2, Standard_E2_V3, Standard_E4_V3, Standard_E8_V3, Standard_E16_V3, Standard_E20_V3, Standard_E32_V3, Standard_E64_V3, Standard_E64i_V3, Standard_E2s_V3, Standard_E4s_V3, Standard_E8s_V3, Standard_E16s_V3, Standard_E20s_V3, Standard_E32s_V3, Standard_E64s_V3, Standard_E64is_V3, Standard_D2a_V4, Standard_D4a_V4, Standard_D8a_V4, Standard_D16a_V4, Standard_D32a_V4, Standard_D48a_V4, Standard_D64a_V4, Standard_D96a_V4, Standard_E2a_V4, Standard_E4a_V4, Standard_E8a_V4, Standard_E16a_V4, Standard_E20a_V4, Standard_E32a_V4, Standard_E48a_V4, Standard_E64a_V4, Standard_E96a_V4, Standard_G1, Standard_G2, Standard_G3, Standard_G4, Standard_G5, Standard_F2s_V2, Standard_F4s_V2, Standard_F8s_V2, Standard_F16s_V2, Standard_F32s_V2, Standard_F64s_V2, Standard_F72s_V2, Standard_GS1, Standard_GS2, Standard_GS3, Standard_GS4, Standard_GS5 and Standard_NC24. Changing this forces a new resource to be created.
	vmSize?: null | string @go(VMSize,*string)

	// The ID of the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	virtualNetworkId?: null | string @go(VirtualNetworkID,*string)
}

#SparkClusterRolesZookeeperNodeParameters: {
	// A list of SSH Keys which should be used for the local administrator on the Zookeeper Nodes. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	sshKeys?: [...null | string] @go(SSHKeys,[]*string)

	// The script action which will run on the cluster. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	scriptActions?: [...#SparkClusterRolesZookeeperNodeScriptActionsParameters] @go(ScriptActions,[]SparkClusterRolesZookeeperNodeScriptActionsParameters)

	// The ID of the Subnet within the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	// +crossplane:generate:reference:type=github.com/upbound/provider-azure/apis/network/v1beta1.Subnet
	// +crossplane:generate:reference:extractor=github.com/upbound/provider-azure/apis/rconfig.ExtractResourceID()
	// +kubebuilder:validation:Optional
	subnetId?: null | string @go(SubnetID,*string)

	// The Username of the local administrator for the Zookeeper Nodes. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	username?: null | string @go(Username,*string)

	// The Size of the Virtual Machine which should be used as the Zookeeper Nodes. Possible values are ExtraSmall, Small, Medium, Large, ExtraLarge, A5, A6, A7, A8, A9, A10, A11, Standard_A1_V2, Standard_A2_V2, Standard_A2m_V2, Standard_A3, Standard_A4_V2, Standard_A4m_V2, Standard_A8_V2, Standard_A8m_V2, Standard_D1, Standard_D2, Standard_D3, Standard_D4, Standard_D11, Standard_D12, Standard_D13, Standard_D14, Standard_D1_V2, Standard_D2_V2, Standard_D3_V2, Standard_D4_V2, Standard_D5_V2, Standard_D11_V2, Standard_D12_V2, Standard_D13_V2, Standard_D14_V2, Standard_DS1_V2, Standard_DS2_V2, Standard_DS3_V2, Standard_DS4_V2, Standard_DS5_V2, Standard_DS11_V2, Standard_DS12_V2, Standard_DS13_V2, Standard_DS14_V2, Standard_E2_V3, Standard_E4_V3, Standard_E8_V3, Standard_E16_V3, Standard_E20_V3, Standard_E32_V3, Standard_E64_V3, Standard_E64i_V3, Standard_E2s_V3, Standard_E4s_V3, Standard_E8s_V3, Standard_E16s_V3, Standard_E20s_V3, Standard_E32s_V3, Standard_E64s_V3, Standard_E64is_V3, Standard_D2a_V4, Standard_D4a_V4, Standard_D8a_V4, Standard_D16a_V4, Standard_D32a_V4, Standard_D48a_V4, Standard_D64a_V4, Standard_D96a_V4, Standard_E2a_V4, Standard_E4a_V4, Standard_E8a_V4, Standard_E16a_V4, Standard_E20a_V4, Standard_E32a_V4, Standard_E48a_V4, Standard_E64a_V4, Standard_E96a_V4, Standard_G1, Standard_G2, Standard_G3, Standard_G4, Standard_G5, Standard_F2s_V2, Standard_F4s_V2, Standard_F8s_V2, Standard_F16s_V2, Standard_F32s_V2, Standard_F64s_V2, Standard_F72s_V2, Standard_GS1, Standard_GS2, Standard_GS3, Standard_GS4, Standard_GS5 and Standard_NC24. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	vmSize?: null | string @go(VMSize,*string)

	// The ID of the Virtual Network where the Zookeeper Nodes should be provisioned within. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	virtualNetworkId?: null | string @go(VirtualNetworkID,*string)
}

#SparkClusterRolesZookeeperNodeScriptActionsInitParameters: {
	// The name of the script action.
	name?: null | string @go(Name,*string)

	// The parameters for the script provided.
	parameters?: null | string @go(Parameters,*string)

	// The URI to the script.
	uri?: null | string @go(URI,*string)
}

#SparkClusterRolesZookeeperNodeScriptActionsObservation: {
	// The name of the script action.
	name?: null | string @go(Name,*string)

	// The parameters for the script provided.
	parameters?: null | string @go(Parameters,*string)

	// The URI to the script.
	uri?: null | string @go(URI,*string)
}

#SparkClusterRolesZookeeperNodeScriptActionsParameters: {
	// The name of the script action.
	// +kubebuilder:validation:Optional
	name?: null | string @go(Name,*string)

	// The parameters for the script provided.
	// +kubebuilder:validation:Optional
	parameters?: null | string @go(Parameters,*string)

	// The URI to the script.
	// +kubebuilder:validation:Optional
	uri?: null | string @go(URI,*string)
}

#SparkClusterSecurityProfileInitParameters: {
	// The resource ID of the Azure Active Directory Domain Service. Changing this forces a new resource to be created.
	aaddsResourceId?: null | string @go(AaddsResourceID,*string)

	// A list of the distinguished names for the cluster user groups. Changing this forces a new resource to be created.
	clusterUsersGroupDns?: [...null | string] @go(ClusterUsersGroupDNS,[]*string)

	// The name of the Azure Active Directory Domain. Changing this forces a new resource to be created.
	domainName?: null | string @go(DomainName,*string)

	// The username of the Azure Active Directory Domain. Changing this forces a new resource to be created.
	domainUsername?: null | string @go(DomainUsername,*string)

	// A list of the LDAPS URLs to communicate with the Azure Active Directory. Changing this forces a new resource to be created.
	ldapsUrls?: [...null | string] @go(LdapsUrls,[]*string)

	// The User Assigned Identity for the HDInsight Cluster. Changing this forces a new resource to be created.
	msiResourceId?: null | string @go(MsiResourceID,*string)
}

#SparkClusterSecurityProfileObservation: {
	// The resource ID of the Azure Active Directory Domain Service. Changing this forces a new resource to be created.
	aaddsResourceId?: null | string @go(AaddsResourceID,*string)

	// A list of the distinguished names for the cluster user groups. Changing this forces a new resource to be created.
	clusterUsersGroupDns?: [...null | string] @go(ClusterUsersGroupDNS,[]*string)

	// The name of the Azure Active Directory Domain. Changing this forces a new resource to be created.
	domainName?: null | string @go(DomainName,*string)

	// The username of the Azure Active Directory Domain. Changing this forces a new resource to be created.
	domainUsername?: null | string @go(DomainUsername,*string)

	// A list of the LDAPS URLs to communicate with the Azure Active Directory. Changing this forces a new resource to be created.
	ldapsUrls?: [...null | string] @go(LdapsUrls,[]*string)

	// The User Assigned Identity for the HDInsight Cluster. Changing this forces a new resource to be created.
	msiResourceId?: null | string @go(MsiResourceID,*string)
}

#SparkClusterSecurityProfileParameters: {
	// The resource ID of the Azure Active Directory Domain Service. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	aaddsResourceId?: null | string @go(AaddsResourceID,*string)

	// A list of the distinguished names for the cluster user groups. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	clusterUsersGroupDns?: [...null | string] @go(ClusterUsersGroupDNS,[]*string)

	// The name of the Azure Active Directory Domain. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	domainName?: null | string @go(DomainName,*string)

	// The username of the Azure Active Directory Domain. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	domainUsername?: null | string @go(DomainUsername,*string)

	// A list of the LDAPS URLs to communicate with the Azure Active Directory. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	ldapsUrls: [...null | string] @go(LdapsUrls,[]*string)

	// The User Assigned Identity for the HDInsight Cluster. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	msiResourceId?: null | string @go(MsiResourceID,*string)
}

#SparkClusterStorageAccountGen2InitParameters: {
	// The ID of the Gen2 Filesystem. Changing this forces a new resource to be created.
	filesystemId?: null | string @go(FileSystemID,*string)

	// Is this the Default Storage Account for the HDInsight Hadoop Cluster? Changing this forces a new resource to be created.
	isDefault?: null | bool @go(IsDefault,*bool)

	// The ID of Managed Identity to use for accessing the Gen2 filesystem. Changing this forces a new resource to be created.
	managedIdentityResourceId?: null | string @go(ManagedIdentityResourceID,*string)

	// The ID of the Storage Account. Changing this forces a new resource to be created.
	storageResourceId?: null | string @go(StorageResourceID,*string)
}

#SparkClusterStorageAccountGen2Observation: {
	// The ID of the Gen2 Filesystem. Changing this forces a new resource to be created.
	filesystemId?: null | string @go(FileSystemID,*string)

	// Is this the Default Storage Account for the HDInsight Hadoop Cluster? Changing this forces a new resource to be created.
	isDefault?: null | bool @go(IsDefault,*bool)

	// The ID of Managed Identity to use for accessing the Gen2 filesystem. Changing this forces a new resource to be created.
	managedIdentityResourceId?: null | string @go(ManagedIdentityResourceID,*string)

	// The ID of the Storage Account. Changing this forces a new resource to be created.
	storageResourceId?: null | string @go(StorageResourceID,*string)
}

#SparkClusterStorageAccountGen2Parameters: {
	// The ID of the Gen2 Filesystem. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	filesystemId?: null | string @go(FileSystemID,*string)

	// Is this the Default Storage Account for the HDInsight Hadoop Cluster? Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	isDefault?: null | bool @go(IsDefault,*bool)

	// The ID of Managed Identity to use for accessing the Gen2 filesystem. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	managedIdentityResourceId?: null | string @go(ManagedIdentityResourceID,*string)

	// The ID of the Storage Account. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	storageResourceId?: null | string @go(StorageResourceID,*string)
}

#SparkClusterStorageAccountInitParameters: {
	// Is this the Default Storage Account for the HDInsight Hadoop Cluster? Changing this forces a new resource to be created.
	isDefault?: null | bool @go(IsDefault,*bool)

	// The ID of the Storage Account. Changing this forces a new resource to be created.
	storageResourceId?: null | string @go(StorageResourceID,*string)
}

#SparkClusterStorageAccountObservation: {
	// Is this the Default Storage Account for the HDInsight Hadoop Cluster? Changing this forces a new resource to be created.
	isDefault?: null | bool @go(IsDefault,*bool)

	// The ID of the Storage Container. Changing this forces a new resource to be created.
	storageContainerId?: null | string @go(StorageContainerID,*string)

	// The ID of the Storage Account. Changing this forces a new resource to be created.
	storageResourceId?: null | string @go(StorageResourceID,*string)
}

#SparkClusterStorageAccountParameters: {
	// Is this the Default Storage Account for the HDInsight Hadoop Cluster? Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	isDefault?: null | bool @go(IsDefault,*bool)

	// The ID of the Storage Container. Changing this forces a new resource to be created.
	// +crossplane:generate:reference:type=github.com/upbound/provider-azure/apis/storage/v1beta1.Container
	// +crossplane:generate:reference:extractor=github.com/upbound/upjet/pkg/resource.ExtractResourceID()
	// +kubebuilder:validation:Optional
	storageContainerId?: null | string @go(StorageContainerID,*string)

	// The ID of the Storage Account. Changing this forces a new resource to be created.
	// +kubebuilder:validation:Optional
	storageResourceId?: null | string @go(StorageResourceID,*string)
}

#WorkerNodeAutoscaleCapacityInitParameters: {
	// The maximum number of worker nodes to autoscale to based on the cluster's activity.
	maxInstanceCount?: null | float64 @go(MaxInstanceCount,*float64)

	// The minimum number of worker nodes to autoscale to based on the cluster's activity.
	minInstanceCount?: null | float64 @go(MinInstanceCount,*float64)
}

#WorkerNodeAutoscaleCapacityObservation: {
	// The maximum number of worker nodes to autoscale to based on the cluster's activity.
	maxInstanceCount?: null | float64 @go(MaxInstanceCount,*float64)

	// The minimum number of worker nodes to autoscale to based on the cluster's activity.
	minInstanceCount?: null | float64 @go(MinInstanceCount,*float64)
}

#WorkerNodeAutoscaleCapacityParameters: {
	// The maximum number of worker nodes to autoscale to based on the cluster's activity.
	// +kubebuilder:validation:Optional
	maxInstanceCount?: null | float64 @go(MaxInstanceCount,*float64)

	// The minimum number of worker nodes to autoscale to based on the cluster's activity.
	// +kubebuilder:validation:Optional
	minInstanceCount?: null | float64 @go(MinInstanceCount,*float64)
}

#WorkerNodeAutoscaleRecurrenceScheduleInitParameters: {
	// The days of the week to perform autoscale. Possible values are Monday, Tuesday, Wednesday, Thursday, Friday, Saturday and Sunday.
	days?: [...null | string] @go(Days,[]*string)

	// The number of instances which should be run for the Worker Nodes.
	targetInstanceCount?: null | float64 @go(TargetInstanceCount,*float64)

	// The time of day to perform the autoscale in 24hour format.
	time?: null | string @go(Time,*string)
}

#WorkerNodeAutoscaleRecurrenceScheduleObservation: {
	// The days of the week to perform autoscale. Possible values are Monday, Tuesday, Wednesday, Thursday, Friday, Saturday and Sunday.
	days?: [...null | string] @go(Days,[]*string)

	// The number of instances which should be run for the Worker Nodes.
	targetInstanceCount?: null | float64 @go(TargetInstanceCount,*float64)

	// The time of day to perform the autoscale in 24hour format.
	time?: null | string @go(Time,*string)
}

#WorkerNodeAutoscaleRecurrenceScheduleParameters: {
	// The days of the week to perform autoscale. Possible values are Monday, Tuesday, Wednesday, Thursday, Friday, Saturday and Sunday.
	// +kubebuilder:validation:Optional
	days: [...null | string] @go(Days,[]*string)

	// The number of instances which should be run for the Worker Nodes.
	// +kubebuilder:validation:Optional
	targetInstanceCount?: null | float64 @go(TargetInstanceCount,*float64)

	// The time of day to perform the autoscale in 24hour format.
	// +kubebuilder:validation:Optional
	time?: null | string @go(Time,*string)
}

// SparkClusterSpec defines the desired state of SparkCluster
#SparkClusterSpec: {
	forProvider: #SparkClusterParameters @go(ForProvider)

	// THIS IS AN ALPHA FIELD. Do not use it in production. It is not honored
	// unless the relevant Crossplane feature flag is enabled, and may be
	// changed or removed without notice.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	initProvider?: #SparkClusterInitParameters @go(InitProvider)
}

// SparkClusterStatus defines the observed state of SparkCluster.
#SparkClusterStatus: {
	atProvider?: #SparkClusterObservation @go(AtProvider)
}

// SparkCluster is the Schema for the SparkClusters API. Manages a HDInsight Spark Cluster.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:subresource:status
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,azure}
#SparkCluster: {
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.clusterVersion) || (has(self.initProvider) && has(self.initProvider.clusterVersion))",message="spec.forProvider.clusterVersion is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.componentVersion) || (has(self.initProvider) && has(self.initProvider.componentVersion))",message="spec.forProvider.componentVersion is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.gateway) || (has(self.initProvider) && has(self.initProvider.gateway))",message="spec.forProvider.gateway is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.location) || (has(self.initProvider) && has(self.initProvider.location))",message="spec.forProvider.location is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.roles) || (has(self.initProvider) && has(self.initProvider.roles))",message="spec.forProvider.roles is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.tier) || (has(self.initProvider) && has(self.initProvider.tier))",message="spec.forProvider.tier is a required parameter"
	spec:    #SparkClusterSpec   @go(Spec)
	status?: #SparkClusterStatus @go(Status)
}

// SparkClusterList contains a list of SparkClusters
#SparkClusterList: {
	items: [...#SparkCluster] @go(Items,[]SparkCluster)
}
